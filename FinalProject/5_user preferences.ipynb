{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the reviews file\n",
    "data = pd.read_csv('steam_final.csv',encoding = 'utf-8')\n",
    "data.dropna(how='any', inplace=True)\n",
    "data.drop_duplicates('review', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great Game, terrible optimisation. Hopefully t...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Huh. I actually don't like it. I've 100%-ed ea...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>very trashy talking about the tsev skyrim le</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lag as shit</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precarious policies.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  recommended\n",
       "0  Great Game, terrible optimisation. Hopefully t...        False\n",
       "1  Huh. I actually don't like it. I've 100%-ed ea...        False\n",
       "2       very trashy talking about the tsev skyrim le        False\n",
       "3                                        Lag as shit        False\n",
       "4                               Precarious policies.        False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews=pd.DataFrame(columns=['review','recommended'])\n",
    "reviews['review']=data['review']\n",
    "reviews['recommended']=data['recommended']\n",
    "reviews.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-a09b368e8d61>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  reviews['review'] = reviews['review'].str.replace(r\"\\b\\w+n't\\b\",'not')\n",
      "<ipython-input-4-a09b368e8d61>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  reviews['review'] = reviews['review'].str.replace(r'&#[0-9]+;', '')\n",
      "<ipython-input-4-a09b368e8d61>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  reviews['review'] = reviews['review'].str.replace(r'[^\\w\\s]', '')\n",
      "<ipython-input-4-a09b368e8d61>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  reviews['review'] = reviews['review'].str.replace(r\"[\\u4e00-\\u9fa5]\",'')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great game terrible optimisation hopefully the...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>huh i actually not like it ive 100ed each game...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>very trashy talking about the tsev skyrim le</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lag as shit</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>precarious policies</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  recommended\n",
       "0  great game terrible optimisation hopefully the...        False\n",
       "1  huh i actually not like it ive 100ed each game...        False\n",
       "2       very trashy talking about the tsev skyrim le        False\n",
       "3                                        lag as shit        False\n",
       "4                                precarious policies        False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean up text\n",
    "reviews['review'] = reviews['review'].str.replace(r\"\\b\\w+n't\\b\",'not')\n",
    "reviews['review'] = reviews['review'].str.replace(r'&#[0-9]+;', '')\n",
    "reviews['review'] = reviews['review'].str.replace(r'[^\\w\\s]', '')\n",
    "reviews['review'] = reviews['review'].str.replace(r\"[\\u4e00-\\u9fa5]\",'')\n",
    "reviews['review'] = reviews['review'].str.lower()\n",
    "reviews.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Common Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords are common words that appears frequently in the text but do not provide much meaning/insights for the purpose of NLP analysis. We want to remove those stopwords to reduce dimensionality for TF-IDF analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = list(set(stopwords.words('english')))# see the set of words NLTK considers stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to generate a list of general stopwords: set of words NLTK considers stopwords. We will perform some modifications on this list based on our business case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['just', 'wasn', \"shan't\", 'mustn', 'out', \"mustn't\", 'at', 'd', 'only', \"wasn't\", 'yours', 'are', 'me', 'didn', 'being', 'theirs', 'than', 'and', 'we', 'now', 'isn', 'hers', 'any', 'between', \"aren't\", 'such', 'you', 'there', 'then', \"should've\", 'under', 'aren', 'our', 'both', 'ma', 'up', 'few', 've', 'about', 'how', 'my', 'do', 'their', 'what', 'be', \"needn't\", 'whom', 'until', 'again', 'when', \"you'll\", 'not', 'some', 'down', 'so', 'further', 'needn', \"you've\", 'these', \"that'll\", 'had', 'against', 'of', 'is', 'by', 'other', 'with', 'over', 'doing', \"hasn't\", 'don', 'this', 'in', 'own', 'haven', \"weren't\", 'myself', 'can', 'while', 'shan', 'have', 'for', 'shouldn', \"haven't\", \"don't\", 'does', 'off', 'hasn', 'why', \"isn't\", 'the', 'who', 'on', 'm', 'once', 'i', 'those', 'won', 'was', \"couldn't\", 'as', 'to', 'couldn', 'its', 'ours', 'an', 'but', \"wouldn't\", \"it's\", 'am', \"you're\", 'into', 'o', 'after', 'nor', 'same', 'all', 'because', 'been', 'hadn', 'itself', \"hadn't\", 'above', 'here', \"you'd\", 'during', 'through', 'if', 'll', 're', 'having', 'themselves', 'did', 'that', \"didn't\", 'a', \"shouldn't\", 'from', 'which', 'it', 'should', \"doesn't\", 't', 'each', 'wouldn', 'y', 'ain', 'very', 'where', 'has', \"mightn't\", 'no', 'or', 's', 'too', 'will', 'most', 'before', 'below', 'them', 'doesn', 'ourselves', 'they', 'were', 'more', 'weren', 'yourself', 'your', 'mightn', \"won't\", 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "for word in [\"she's\", \"his\", \"him\", \"she\", \"her\", \"he\", \"herself\", \"himself\"]:\n",
    "    stopwords.remove(word)\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"review\"] = reviews[\"review\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to keep gender related words in this case because they can help us analyze who our customers are and how they reviews our products based on demographic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize reviews\n",
    "reviews[\"review\"] = reviews[\"review\"].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords in reviews\n",
    "def remove_stopwords(tokens):\n",
    "    tokens_copy = tokens.copy()\n",
    "    for word in stopwords:\n",
    "        while word in tokens_copy:\n",
    "            tokens_copy.remove(word)\n",
    "    return tokens_copy\n",
    "reviews[\"removed_tokens\"] = reviews['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great game terrible optimisation hopefully fix instead trying cash grab',\n",
       " 'huh actually like ive 100ed game edmund ive fan minute end nigh came quickly expectations focus far precision platforming meat boys charm fluidity speed precision platforming 100 miles minute far methodical drawn mention lot forced trial error collectables pretty meh cartridges big ticket item however theyre merely stages lofi graphics music great theres odd charm fact 3050 soundrack public domain music remixed gothicrock stylings isaac animations graphics fantastic controls perfect self contained game map stage real cutscenes yes must backtrack world entirety search collectables mileage may one real charm bland color scheme world little variety mostly waiting jumping right spot repeat opposed meat boys dynamic levels far obstacles variety different mechanics speed kept things fresh end nigh basically meat boy distilled main mechanics remove wall jumping sprint switch focus fluidity precision platforming dull stages never feel like change collectables feel empty unrewarding',\n",
       " 'trashy talking tsev skyrim le',\n",
       " 'lag shit',\n",
       " 'precarious policies',\n",
       " 'never liked game anyway',\n",
       " 'need chinese eu4 third party52 muyou party made us chinese experience eu4but paradox never done chinese localization hope paradox make chinese version soon possible eu4eu4pp',\n",
       " 'fuck assholes',\n",
       " 'im torn game really smartly designed played game like phone less 3 maybe even free im sure called night full moon arguably looks better though suffers problems recommend paying 25 essentially well made mobile game buy sale deeeeep sale',\n",
       " 'boring']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_removed_tokens = [\" \".join(i) for i in reviews[\"removed_tokens\"]]\n",
    "reviews_removed_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove consecutively repeated patterns\n",
    "reviews_removed_tokens = [re.sub(r'^(.+?)\\1+', r'\\1', i) for i in reviews_removed_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would choose lemmatization because it is less aggressive and keeps the original form of a word. This avoids confusion caused by stemming because it reduces words to its original form. Lemmatization also considers words within the context, would could be more accurate in many ways when we perform NLP data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_texts = []\n",
    "for text in reviews_removed_tokens:\n",
    "    cleaned_texts.append(lemmatize_sentence(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe is (64122, 200)\n",
      "Total number of occurences: 539538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '100',\n",
       " '1010',\n",
       " '20',\n",
       " 'able',\n",
       " 'absolutely',\n",
       " 'access',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'ai',\n",
       " 'amaze',\n",
       " 'amazing',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'bad',\n",
       " 'base',\n",
       " 'best',\n",
       " 'big',\n",
       " 'bit',\n",
       " 'bore',\n",
       " 'boring',\n",
       " 'break',\n",
       " 'bug',\n",
       " 'build',\n",
       " 'buy',\n",
       " 'care',\n",
       " 'challenge',\n",
       " 'change',\n",
       " 'character',\n",
       " 'combat',\n",
       " 'come',\n",
       " 'community',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'content',\n",
       " 'control',\n",
       " 'cool',\n",
       " 'crash',\n",
       " 'day',\n",
       " 'design',\n",
       " 'developer',\n",
       " 'devs',\n",
       " 'die',\n",
       " 'different',\n",
       " 'dlc',\n",
       " 'dont',\n",
       " 'drop',\n",
       " 'early',\n",
       " 'easy',\n",
       " 'end',\n",
       " 'enemy',\n",
       " 'enjoy',\n",
       " 'especially',\n",
       " 'expect',\n",
       " 'experience',\n",
       " 'fact',\n",
       " 'fan',\n",
       " 'far',\n",
       " 'feature',\n",
       " 'feel',\n",
       " 'fight',\n",
       " 'finish',\n",
       " 'fix',\n",
       " 'force',\n",
       " 'fps',\n",
       " 'free',\n",
       " 'friend',\n",
       " 'fuck',\n",
       " 'fun',\n",
       " 'game',\n",
       " 'gameplay',\n",
       " 'good',\n",
       " 'graphic',\n",
       " 'great',\n",
       " 'guy',\n",
       " 'half',\n",
       " 'happen',\n",
       " 'hard',\n",
       " 'hell',\n",
       " 'help',\n",
       " 'high',\n",
       " 'hit',\n",
       " 'honestly',\n",
       " 'hope',\n",
       " 'hour',\n",
       " 'huge',\n",
       " 'id',\n",
       " 'idea',\n",
       " 'im',\n",
       " 'instead',\n",
       " 'issue',\n",
       " 'item',\n",
       " 'ive',\n",
       " 'kill',\n",
       " 'kind',\n",
       " 'know',\n",
       " 'lack',\n",
       " 'learn',\n",
       " 'leave',\n",
       " 'let',\n",
       " 'level',\n",
       " 'life',\n",
       " 'like',\n",
       " 'literally',\n",
       " 'little',\n",
       " 'load',\n",
       " 'long',\n",
       " 'look',\n",
       " 'lose',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'low',\n",
       " 'main',\n",
       " 'make',\n",
       " 'map',\n",
       " 'maybe',\n",
       " 'mean',\n",
       " 'mechanic',\n",
       " 'minute',\n",
       " 'mission',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'money',\n",
       " 'multiplayer',\n",
       " 'need',\n",
       " 'new',\n",
       " 'nice',\n",
       " 'old',\n",
       " 'online',\n",
       " 'open',\n",
       " 'option',\n",
       " 'overall',\n",
       " 'pay',\n",
       " 'pc',\n",
       " 'people',\n",
       " 'place',\n",
       " 'play',\n",
       " 'player',\n",
       " 'playing',\n",
       " 'point',\n",
       " 'pretty',\n",
       " 'price',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'quite',\n",
       " 'real',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'recommend',\n",
       " 'refund',\n",
       " 'release',\n",
       " 'review',\n",
       " 'right',\n",
       " 'ruin',\n",
       " 'run',\n",
       " 'sale',\n",
       " 'save',\n",
       " 'say',\n",
       " 'screen',\n",
       " 'second',\n",
       " 'server',\n",
       " 'set',\n",
       " 'shit',\n",
       " 'single',\n",
       " 'small',\n",
       " 'spend',\n",
       " 'start',\n",
       " 'steam',\n",
       " 'stop',\n",
       " 'story',\n",
       " 'stuff',\n",
       " 'suck',\n",
       " 'support',\n",
       " 'sure',\n",
       " 'team',\n",
       " 'tell',\n",
       " 'terrible',\n",
       " 'thats',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'time',\n",
       " 'try',\n",
       " 'turn',\n",
       " 'unless',\n",
       " 'update',\n",
       " 'use',\n",
       " 'version',\n",
       " 'wait',\n",
       " 'want',\n",
       " 'waste',\n",
       " 'way',\n",
       " 'weapon',\n",
       " 'wish',\n",
       " 'work',\n",
       " 'world',\n",
       " 'worth',\n",
       " 'year',\n",
       " 'yes',\n",
       " 'youll',\n",
       " 'youre']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words = 'english',binary = True, min_df =0.005, max_features=200)\n",
    "X = vectorizer.fit_transform(cleaned_texts)\n",
    "\n",
    "vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "print(f\"Shape of dataframe is {vectorized_df.shape}\")\n",
    "print(f\"Total number of occurences: {vectorized_df.sum().sum()}\")\n",
    "#print(f\"Word counts: {vectorized_df.sum()}\")\n",
    "list(vectorized_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_df = pd.DataFrame(cleaned_texts)\n",
    "#cleaned_df.to_csv('cleaned_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>recommended</th>\n",
       "      <th>removed_tokens</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[great, game, terrible, optimisation, hopefull...</td>\n",
       "      <td>False</td>\n",
       "      <td>[great, game, terrible, optimisation, hopefull...</td>\n",
       "      <td>good game terrible optimisation hopefully fix ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[huh, i, actually, not, like, it, ive, 100ed, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[huh, actually, like, ive, 100ed, game, edmund...</td>\n",
       "      <td>huh actually like i have 100ed game edmund i h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[very, trashy, talking, about, the, tsev, skyr...</td>\n",
       "      <td>False</td>\n",
       "      <td>[trashy, talking, tsev, skyrim, le]</td>\n",
       "      <td>trashy talk tsev skyrim le</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[lag, as, shit]</td>\n",
       "      <td>False</td>\n",
       "      <td>[lag, shit]</td>\n",
       "      <td>lag shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[precarious, policies]</td>\n",
       "      <td>False</td>\n",
       "      <td>[precarious, policies]</td>\n",
       "      <td>precarious policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[i, never, liked, this, game, anyway]</td>\n",
       "      <td>False</td>\n",
       "      <td>[never, liked, game, anyway]</td>\n",
       "      <td>never like game anyway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[we, need, chinese, about, eu4, the, third, pa...</td>\n",
       "      <td>False</td>\n",
       "      <td>[need, chinese, eu4, third, party52, muyou, pa...</td>\n",
       "      <td>need chinese eu4 third party52 muyou party mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[fuck, these, assholes]</td>\n",
       "      <td>False</td>\n",
       "      <td>[fuck, assholes]</td>\n",
       "      <td>fuck asshole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[im, torn, this, game, really, is, smartly, de...</td>\n",
       "      <td>False</td>\n",
       "      <td>[im, torn, game, really, smartly, designed, pl...</td>\n",
       "      <td>im torn game really smartly design played game...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[boring]</td>\n",
       "      <td>False</td>\n",
       "      <td>[boring]</td>\n",
       "      <td>boring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  recommended  \\\n",
       "0  [great, game, terrible, optimisation, hopefull...        False   \n",
       "1  [huh, i, actually, not, like, it, ive, 100ed, ...        False   \n",
       "2  [very, trashy, talking, about, the, tsev, skyr...        False   \n",
       "3                                    [lag, as, shit]        False   \n",
       "4                             [precarious, policies]        False   \n",
       "5              [i, never, liked, this, game, anyway]        False   \n",
       "6  [we, need, chinese, about, eu4, the, third, pa...        False   \n",
       "7                            [fuck, these, assholes]        False   \n",
       "8  [im, torn, this, game, really, is, smartly, de...        False   \n",
       "9                                           [boring]        False   \n",
       "\n",
       "                                      removed_tokens  \\\n",
       "0  [great, game, terrible, optimisation, hopefull...   \n",
       "1  [huh, actually, like, ive, 100ed, game, edmund...   \n",
       "2                [trashy, talking, tsev, skyrim, le]   \n",
       "3                                        [lag, shit]   \n",
       "4                             [precarious, policies]   \n",
       "5                       [never, liked, game, anyway]   \n",
       "6  [need, chinese, eu4, third, party52, muyou, pa...   \n",
       "7                                   [fuck, assholes]   \n",
       "8  [im, torn, game, really, smartly, designed, pl...   \n",
       "9                                           [boring]   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  good game terrible optimisation hopefully fix ...  \n",
       "1  huh actually like i have 100ed game edmund i h...  \n",
       "2                         trashy talk tsev skyrim le  \n",
       "3                                           lag shit  \n",
       "4                                  precarious policy  \n",
       "5                             never like game anyway  \n",
       "6  need chinese eu4 third party52 muyou party mak...  \n",
       "7                                       fuck asshole  \n",
       "8  im torn game really smartly design played game...  \n",
       "9                                             boring  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from textacy.preprocessing.replace import urls, hashtags, numbers, emails, emojis, currency_symbols\n",
    "for i in range(len(cleaned_texts)):\n",
    "    cleaned_texts[i] = re.sub(r\"\\b\\w+n't\\b\",'not',cleaned_texts[i],flags = re.IGNORECASE)\n",
    "    cleaned_texts[i] = re.sub(r'id\\b','i would',cleaned_texts[i],flags = re.IGNORECASE)\n",
    "    cleaned_texts[i] = re.sub(r'\\byouve\\b','you have',cleaned_texts[i],flags = re.IGNORECASE)\n",
    "    cleaned_texts[i] = re.sub(r'\\bive\\b','i have',cleaned_texts[i],flags = re.IGNORECASE)\n",
    "    cleaned_texts[i] = re.sub(r'br\\b',' ',cleaned_texts[i],flags = re.IGNORECASE)\n",
    "    cleaned_texts[i] = re.sub(r'\\bn?o+?\\b','no',cleaned_texts[i],flags = re.IGNORECASE)\n",
    "    cleaned_texts[i] = re.sub(r'\\bb+?a+?d+?\\b','bad',cleaned_texts[i],flags = re.IGNORECASE)\n",
    "    cleaned_texts[i] = re.sub(r'\\bg+?o+?d+?\\b','good',cleaned_texts[i],flags = re.IGNORECASE)\n",
    "    cleaned_texts[i] = re.sub(r'\\bgreat\\b','good',cleaned_texts[i],flags = re.IGNORECASE)\n",
    "    cleaned_texts[i] = re.sub(r'\\bbest\\b','good',cleaned_texts[i],flags = re.IGNORECASE)\n",
    "    cleaned_texts[i] = re.sub(r'\\bamazing\\b','good',cleaned_texts[i],flags = re.IGNORECASE)\n",
    "    cleaned_texts[i] = re.sub(r'\\bevery time\\b','',cleaned_texts[i],flags = re.IGNORECASE)\n",
    "    cleaned_texts[i] = re.sub(r'\\blook like\\b','',cleaned_texts[i],flags = re.IGNORECASE)\n",
    "    cleaned_texts[i] = re.sub(r'\\bseem likeb','',cleaned_texts[i],flags = re.IGNORECASE)\n",
    "    cleaned_texts[i] = numbers(cleaned_texts[i])\n",
    "reviews['cleaned_text'] = cleaned_texts\n",
    "reviews.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.extend(['steam', 'platform', 'another', 'huh', 'also', 'game', 'like', 'play', 'get', 'good', 'make', 'feel', 'take', 'time', 'one', 'games', 'would', 'hours', 'playing', 'people', 'played', 'im', 'first', 'also', 'every', 'many', 'go', 'got', '2', 'could', 'back', 'things'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to remove some words that are too general in our context. For example, steam and platform. Since we are analyzing steam reviews, the word \"steam\" could be mentioned multiple times, but it does not help much with understanding the pattern. We also want to remove some common words in the documents according to the word count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.extend(['always', 'very', 'really', 'totally', 'definitely', 'especially', 'only', 'absolutely', 'exactly', 'equally', 'perfectly', 'obsolutely', 'highly', 'mostly', 'hopefully', 'anyway','would','could', 'really', 'even', 'definitely',\n",
    "             'still', 'bit', 'way','absolutely', 'almost', 'enough','ever','much','pretty','seem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.extend(['region','lock','waste','money','worth','price','full','single','player','bug','bugs','load','screen','_number_'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to remove some adverbs that emphasis certain verbs. They are useful in emphasisng, but not as useful in NLP when we tokenize words and look at adverbs and verbs alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"cleaned_text\"] = reviews[\"cleaned_text\"].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords in cleaned reviews\n",
    "reviews[\"final_text\"] = reviews['cleaned_text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>recommended</th>\n",
       "      <th>removed_tokens</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[great, game, terrible, optimisation, hopefull...</td>\n",
       "      <td>False</td>\n",
       "      <td>[great, game, terrible, optimisation, hopefull...</td>\n",
       "      <td>[good, game, terrible, optimisation, hopefully...</td>\n",
       "      <td>terrible optimisation fix instead try cash grab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[huh, i, actually, not, like, it, ive, 100ed, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[huh, actually, like, ive, 100ed, game, edmund...</td>\n",
       "      <td>[huh, actually, like, i, have, 100ed, game, ed...</td>\n",
       "      <td>actually 100ed edmund fan minute end nigh come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[very, trashy, talking, about, the, tsev, skyr...</td>\n",
       "      <td>False</td>\n",
       "      <td>[trashy, talking, tsev, skyrim, le]</td>\n",
       "      <td>[trashy, talk, tsev, skyrim, le]</td>\n",
       "      <td>trashy talk tsev skyrim le</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[lag, as, shit]</td>\n",
       "      <td>False</td>\n",
       "      <td>[lag, shit]</td>\n",
       "      <td>[lag, shit]</td>\n",
       "      <td>lag shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[precarious, policies]</td>\n",
       "      <td>False</td>\n",
       "      <td>[precarious, policies]</td>\n",
       "      <td>[precarious, policy]</td>\n",
       "      <td>precarious policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[i, never, liked, this, game, anyway]</td>\n",
       "      <td>False</td>\n",
       "      <td>[never, liked, game, anyway]</td>\n",
       "      <td>[never, like, game, anyway]</td>\n",
       "      <td>never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[we, need, chinese, about, eu4, the, third, pa...</td>\n",
       "      <td>False</td>\n",
       "      <td>[need, chinese, eu4, third, party52, muyou, pa...</td>\n",
       "      <td>[need, chinese, eu4, third, party52, muyou, pa...</td>\n",
       "      <td>need chinese eu4 third party52 muyou party us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[fuck, these, assholes]</td>\n",
       "      <td>False</td>\n",
       "      <td>[fuck, assholes]</td>\n",
       "      <td>[fuck, asshole]</td>\n",
       "      <td>fuck asshole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[im, torn, this, game, really, is, smartly, de...</td>\n",
       "      <td>False</td>\n",
       "      <td>[im, torn, game, really, smartly, designed, pl...</td>\n",
       "      <td>[im, torn, game, really, smartly, design, play...</td>\n",
       "      <td>torn smartly design phone less _NUMBER_ maybe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[boring]</td>\n",
       "      <td>False</td>\n",
       "      <td>[boring]</td>\n",
       "      <td>[boring]</td>\n",
       "      <td>boring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  recommended  \\\n",
       "0  [great, game, terrible, optimisation, hopefull...        False   \n",
       "1  [huh, i, actually, not, like, it, ive, 100ed, ...        False   \n",
       "2  [very, trashy, talking, about, the, tsev, skyr...        False   \n",
       "3                                    [lag, as, shit]        False   \n",
       "4                             [precarious, policies]        False   \n",
       "5              [i, never, liked, this, game, anyway]        False   \n",
       "6  [we, need, chinese, about, eu4, the, third, pa...        False   \n",
       "7                            [fuck, these, assholes]        False   \n",
       "8  [im, torn, this, game, really, is, smartly, de...        False   \n",
       "9                                           [boring]        False   \n",
       "\n",
       "                                      removed_tokens  \\\n",
       "0  [great, game, terrible, optimisation, hopefull...   \n",
       "1  [huh, actually, like, ive, 100ed, game, edmund...   \n",
       "2                [trashy, talking, tsev, skyrim, le]   \n",
       "3                                        [lag, shit]   \n",
       "4                             [precarious, policies]   \n",
       "5                       [never, liked, game, anyway]   \n",
       "6  [need, chinese, eu4, third, party52, muyou, pa...   \n",
       "7                                   [fuck, assholes]   \n",
       "8  [im, torn, game, really, smartly, designed, pl...   \n",
       "9                                           [boring]   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  [good, game, terrible, optimisation, hopefully...   \n",
       "1  [huh, actually, like, i, have, 100ed, game, ed...   \n",
       "2                   [trashy, talk, tsev, skyrim, le]   \n",
       "3                                        [lag, shit]   \n",
       "4                               [precarious, policy]   \n",
       "5                        [never, like, game, anyway]   \n",
       "6  [need, chinese, eu4, third, party52, muyou, pa...   \n",
       "7                                    [fuck, asshole]   \n",
       "8  [im, torn, game, really, smartly, design, play...   \n",
       "9                                           [boring]   \n",
       "\n",
       "                                          final_text  \n",
       "0    terrible optimisation fix instead try cash grab  \n",
       "1  actually 100ed edmund fan minute end nigh come...  \n",
       "2                         trashy talk tsev skyrim le  \n",
       "3                                           lag shit  \n",
       "4                                  precarious policy  \n",
       "5                                              never  \n",
       "6  need chinese eu4 third party52 muyou party us ...  \n",
       "7                                       fuck asshole  \n",
       "8  torn smartly design phone less _NUMBER_ maybe ...  \n",
       "9                                             boring  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[\"final_text\"] = [\" \".join(i) for i in reviews[\"final_text\"]]\n",
    "reviews.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a single without any context usually does not provide much useful information for analysis, we decided to try n-grams of 2, 3, and 4 to determine which would be the most suitable n-gram for our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_review=reviews[reviews['recommended']==True]\n",
    "poor_review=reviews[reviews['recommended']==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### good_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Common reasons with n-grams of 2:\n",
      "                       score\n",
      "fun friend        281.430182\n",
      "lot fun           190.686628\n",
      "early access      139.572007\n",
      "open world        121.146081\n",
      "recommend anyone  109.564439\n",
      "dark soul         104.708464\n",
      "super fun         101.795878\n",
      "total war          94.524035\n",
      "look forward       92.343743\n",
      "art style          72.984692\n",
      "story line         70.744077\n",
      "learn curve        70.263756\n",
      "replay value       68.419024\n",
      "spend hour         64.984784\n",
      "fun recommend      60.008835\n",
      "easy learn         58.044538\n",
      "fun friends        57.184770\n",
      "write review       56.702865\n",
      "must buy           56.625234\n",
      "hour fun           55.368190\n",
      "\n",
      "Top 20 Common reasons with n-grams of 3:\n",
      "                            score\n",
      "learn hard master       29.474658\n",
      "easy learn hard         29.356972\n",
      "steep learn curve       27.747872\n",
      "grand theft auto        21.219674\n",
      "lot fun friend          20.937334\n",
      "total war series        20.749579\n",
      "recommend anyone enjoy  17.842134\n",
      "recommend anyone want   17.447755\n",
      "recommend anyone look   17.243714\n",
      "look forward see        16.653555\n",
      "hour upon hour          16.424711\n",
      "cant wait see           16.414056\n",
      "dream come true         15.681902\n",
      "factory must grow       14.667761\n",
      "turn base strategy      13.421525\n",
      "open world rpg          13.370802\n",
      "high skill ceiling      13.142483\n",
      "lot replay value        13.119713\n",
      "rainbow six siege       13.086935\n",
      "super fun friend        12.070968\n",
      "\n",
      "Top 20 Common reasons with n-grams of 4:\n",
      "                                     score\n",
      "easy learn hard master           36.867714\n",
      "doki doki literature club         7.000000\n",
      "easy learn difficult master       6.416729\n",
      "brave new world expansion         6.000000\n",
      "harvest moon animal cross         6.000000\n",
      "harvest moon rune factory         5.000000\n",
      "animal cross harvest moon         4.374101\n",
      "jurassic park operation genesis   4.363747\n",
      "wait see future hold              4.000000\n",
      "south park stick truth            4.000000\n",
      "hour upon hour gameplay           4.000000\n",
      "fallout new vega fallout          4.000000\n",
      "hard learn hard master            3.688761\n",
      "steep learn curve new             3.377522\n",
      "grand theft auto series           3.246393\n",
      "learn hard master fun             3.044043\n",
      "easy learn impossible master      3.000000\n",
      "counter strike global offensive   3.000000\n",
      "hold special place heart          3.000000\n",
      "main story side quest             3.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "for i in range(2, 5):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(i,i),\n",
    "                             binary=True,\n",
    "                             max_features=1000,\n",
    "                             token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                             stop_words=stopwords)\n",
    "    \n",
    "    X = vectorizer.fit_transform(good_review[\"final_text\"])\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "    tf_idf = tf_idf.sum(axis=1)\n",
    "    score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "    score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "    print(f'Top 20 Common reasons with n-grams of {i}:')\n",
    "    print(\"{}\\n\".format(score.head(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### poor_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Common reasons with n-grams of 2:\n",
      "                       score\n",
      "early access      324.041088\n",
      "dont buy          273.793540\n",
      "pay mod           257.658828\n",
      "current state     142.054731\n",
      "negative review   130.083835\n",
      "year old          127.631353\n",
      "total war         114.137692\n",
      "year ago          114.013738\n",
      "pay win           112.790483\n",
      "creation club     109.016242\n",
      "gta online        107.608684\n",
      "piece shit        107.333694\n",
      "run around        105.220373\n",
      "recommend anyone  103.905840\n",
      "stay away         103.135008\n",
      "spend hour         95.602849\n",
      "dont know          93.736584\n",
      "open world         92.121947\n",
      "combat system      88.305443\n",
      "new update         88.221435\n",
      "\n",
      "Top 20 Common reasons with n-grams of 3:\n",
      "                             score\n",
      "recommend current state  59.771744\n",
      "give negative review     53.539823\n",
      "fallout new vega         47.007133\n",
      "buy shark card           46.039478\n",
      "give positive review     36.125453\n",
      "dlc early access         34.249450\n",
      "grand theft auto         29.417508\n",
      "need lot work            25.161730\n",
      "shit dont buy            23.811860\n",
      "dont buy unless          22.903206\n",
      "write negative review    22.566133\n",
      "leave negative review    21.688897\n",
      "rainbow six siege        21.305121\n",
      "early access title       21.140968\n",
      "let start say            20.816267\n",
      "ark survival evolve      20.730239\n",
      "long story short         20.666067\n",
      "release early access     19.639848\n",
      "give bad review          18.401768\n",
      "frame rate drop          17.469725\n",
      "\n",
      "Top 20 Common reasons with n-grams of 4:\n",
      "                                    score\n",
      "pay dlc early access            18.190295\n",
      "creation club pay mod           16.864395\n",
      "early access pay dlc            11.000000\n",
      "leave bad taste mouth            8.000000\n",
      "release dlc early access         7.545182\n",
      "mile wide inch deep              7.000000\n",
      "pay mod creation club            6.685453\n",
      "easy learn hard master           6.523564\n",
      "fallout fallout new vega         6.387549\n",
      "reason give negative review      6.000000\n",
      "leave sour taste mouth           6.000000\n",
      "recommend buy current state      6.000000\n",
      "pay mod pay mod                  5.747269\n",
      "stay far far away                5.676243\n",
      "fallout new vega fallout         5.047158\n",
      "recommend anyone current state   5.000000\n",
      "review censor republic china     5.000000\n",
      "spend hour upon hour             5.000000\n",
      "dont buy unless want             4.918089\n",
      "dark soul dark soul              4.791841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "for i in range(2, 5):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(i,i),\n",
    "                             binary=True,\n",
    "                             max_features=1000,\n",
    "                             token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                             stop_words=stopwords)\n",
    "    \n",
    "    X = vectorizer.fit_transform(poor_review[\"final_text\"])\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "    tf_idf = tf_idf.sum(axis=1)\n",
    "    score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "    score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "    print(f'Top 20 Common reasons with n-grams of {i}:')\n",
    "    print(\"{}\\n\".format(score.head(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the TF-IDF scores calculated above, we can determine that customer's review for Steam are both from the positive and negative directions. Based on the analysis, we have gathered some general common themes in good reviews. These themes can be addressed with different functional teams in the company.\n",
    "\n",
    "The most common themes in poor reviews that can be addressed with different teams are:\n",
    "\n",
    "Sales and marketing teams:\n",
    "- worth and reasonable pricing\n",
    "\n",
    "Game design teams (art, engineering, strategy, game planning):\n",
    "- fun to play with friends\n",
    "- game content (art style, story line, etc.)\n",
    "- game play features (open world, early access etc.)\n",
    "\n",
    "\n",
    "The most common themes in poor reviews that can be addressed with different teams are:\n",
    "\n",
    "Operations, sales and marketing teams:\n",
    "- age and region block\n",
    "- not worth the money spent\n",
    "\n",
    "Game design teams:\n",
    "- single player mode\n",
    "- game play experience (load screen, bugs, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting the most common themes of all comments, we want to take a look at each categories in more details and see what stands out in each theme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-855a247d7a4b>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  good_review['fun_friend'] = good_review['final_text'].str.contains(r'lot fun|fun friend|super fun|lot fun friend')\n",
      "<ipython-input-47-855a247d7a4b>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  good_review['worth_money'] = good_review['final_text'].str.contains(r'worth money|recommend anyone|well worth|worth price|full price|full recommend|worth full price|well worth moeny|buy full price|well worth price')\n",
      "<ipython-input-47-855a247d7a4b>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  good_review['game_content'] = good_review['final_text'].str.contains(r'story line|art style|learn curve|learn hard master|steep learn curve')\n",
      "<ipython-input-47-855a247d7a4b>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  good_review['game_play'] = good_review['final_text'].str.contains(r'open world|early access|turn base strategy|single player campaign')\n",
      "<ipython-input-47-855a247d7a4b>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  poor_review['region_lock'] = poor_review['final_text'].str.contains(r'region lock|regionlocking')\n",
      "<ipython-input-47-855a247d7a4b>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  poor_review['not_worthy'] = poor_review['final_text'].str.contains(r'waste money|worth price|worth full price|pay mod|dont buy unless')\n",
      "<ipython-input-47-855a247d7a4b>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  poor_review['single_player'] = poor_review['final_text'].str.contains(r'single player|single|multiplayer')\n",
      "<ipython-input-47-855a247d7a4b>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  poor_review['game_exp'] = poor_review['final_text'].str.contains(r'bug|bugs|load screen|need lot work|early access')\n"
     ]
    }
   ],
   "source": [
    "#positive reviews\n",
    "good_review['fun_friend'] = good_review['final_text'].str.contains(r'lot fun|fun friend|super fun|lot fun friend')\n",
    "good_review['worth_money'] = good_review['final_text'].str.contains(r'worth money|recommend anyone|well worth|worth price|full price|full recommend|worth full price|well worth moeny|buy full price|well worth price')\n",
    "good_review['game_content'] = good_review['final_text'].str.contains(r'story line|art style|learn curve|learn hard master|steep learn curve')\n",
    "good_review['game_play'] = good_review['final_text'].str.contains(r'open world|early access|turn base strategy|single player campaign')\n",
    "\n",
    "#negative reviews\n",
    "poor_review['region_lock'] = poor_review['final_text'].str.contains(r'region lock|regionlocking')\n",
    "poor_review['not_worthy'] = poor_review['final_text'].str.contains(r'waste money|worth price|worth full price|pay mod|dont buy unless')\n",
    "poor_review['single_player'] = poor_review['final_text'].str.contains(r'single player|single|multiplayer')\n",
    "poor_review['game_exp'] = poor_review['final_text'].str.contains(r'bug|bugs|load screen|need lot work|early access')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Common theme related to fun friend reviews with n-grams of 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lot fun friend</th>\n",
       "      <td>6.935260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super fun friend</th>\n",
       "      <td>6.320107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extremely fun friend</th>\n",
       "      <td>4.577513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun friend recommend</th>\n",
       "      <td>3.811397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun friend fun</th>\n",
       "      <td>3.589771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amaze fun friend</th>\n",
       "      <td>2.899047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alot fun friend</th>\n",
       "      <td>2.837891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun friend solo</th>\n",
       "      <td>2.284137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun friend online</th>\n",
       "      <td>2.251716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun friends _number_</th>\n",
       "      <td>2.215920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         score\n",
       "lot fun friend        6.935260\n",
       "super fun friend      6.320107\n",
       "extremely fun friend  4.577513\n",
       "fun friend recommend  3.811397\n",
       "fun friend fun        3.589771\n",
       "amaze fun friend      2.899047\n",
       "alot fun friend       2.837891\n",
       "fun friend solo       2.284137\n",
       "fun friend online     2.251716\n",
       "fun friends _number_  2.215920"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun_friend = good_review[good_review['fun_friend'] == True ]['final_text'].values\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3,3) )\n",
    "X = vectorizer.fit_transform(fun_friend)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "print(\"Top 10 Common theme related to fun friend reviews with n-grams of 3\")\n",
    "(score.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Common theme related to worthy of money reviews with n-grams of 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recommend anyone enjoy</th>\n",
       "      <td>2.755082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_number_ recommend anyone</th>\n",
       "      <td>2.665011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommend anyone look</th>\n",
       "      <td>2.589169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommend anyone want</th>\n",
       "      <td>2.443731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommend anyone love</th>\n",
       "      <td>2.349824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun recommend anyone</th>\n",
       "      <td>2.337154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommend anyone interested</th>\n",
       "      <td>1.700756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strongly recommend anyone</th>\n",
       "      <td>1.603435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommend anyone friend</th>\n",
       "      <td>1.424995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love recommend anyone</th>\n",
       "      <td>1.360880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                score\n",
       "recommend anyone enjoy       2.755082\n",
       "_number_ recommend anyone    2.665011\n",
       "recommend anyone look        2.589169\n",
       "recommend anyone want        2.443731\n",
       "recommend anyone love        2.349824\n",
       "fun recommend anyone         2.337154\n",
       "recommend anyone interested  1.700756\n",
       "strongly recommend anyone    1.603435\n",
       "recommend anyone friend      1.424995\n",
       "love recommend anyone        1.360880"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worth_money = good_review[good_review['worth_money'] == True ]['final_text'].values\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3,3) )\n",
    "X = vectorizer.fit_transform(worth_money)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "print(\"Top 10 Common theme related to worthy of money reviews with n-grams of 3\")\n",
    "score.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Common theme related to game content reviews with n-grams of 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learn hard master</th>\n",
       "      <td>7.538876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy learn hard</th>\n",
       "      <td>7.350267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steep learn curve</th>\n",
       "      <td>4.706471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love art style</th>\n",
       "      <td>2.698874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learn curve fun</th>\n",
       "      <td>2.690482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_number_ _number_ hour</th>\n",
       "      <td>2.410251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>art style music</th>\n",
       "      <td>1.818224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short _number_ _number_</th>\n",
       "      <td>1.619025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story line overall</th>\n",
       "      <td>1.606521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>significant brain usage</th>\n",
       "      <td>1.478926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            score\n",
       "learn hard master        7.538876\n",
       "easy learn hard          7.350267\n",
       "steep learn curve        4.706471\n",
       "love art style           2.698874\n",
       "learn curve fun          2.690482\n",
       "_number_ _number_ hour   2.410251\n",
       "art style music          1.818224\n",
       "short _number_ _number_  1.619025\n",
       "story line overall       1.606521\n",
       "significant brain usage  1.478926"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_content = good_review[good_review['game_content'] == True ]['final_text'].values\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3,3) )\n",
    "X = vectorizer.fit_transform(game_content)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "print(\"Top 10 Common theme related to game content reviews with n-grams of 3\")\n",
    "score.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Common theme related to game play reviews with n-grams of 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>open world rpg</th>\n",
       "      <td>3.703285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amaze open world</th>\n",
       "      <td>3.679078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open world _number_</th>\n",
       "      <td>2.861091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turn base strategy</th>\n",
       "      <td>2.473814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>though early access</th>\n",
       "      <td>2.215124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love open world</th>\n",
       "      <td>2.078421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early access fun</th>\n",
       "      <td>2.012725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open world survival</th>\n",
       "      <td>1.914062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy early access</th>\n",
       "      <td>1.633320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>since early access</th>\n",
       "      <td>1.566592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        score\n",
       "open world rpg       3.703285\n",
       "amaze open world     3.679078\n",
       "open world _number_  2.861091\n",
       "turn base strategy   2.473814\n",
       "though early access  2.215124\n",
       "love open world      2.078421\n",
       "early access fun     2.012725\n",
       "open world survival  1.914062\n",
       "buy early access     1.633320\n",
       "since early access   1.566592"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_play = good_review[good_review['game_play'] == True ]['final_text'].values\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3,3) )\n",
    "X = vectorizer.fit_transform(game_play)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "print(\"Top 10 Common theme related to game play reviews with n-grams of 3\")\n",
    "score.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Common theme related to region locking reviews with n-grams of 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zone competitive world</th>\n",
       "      <td>0.11547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>properly organize community</th>\n",
       "      <td>0.11547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour come hard</th>\n",
       "      <td>0.11547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real problem progress</th>\n",
       "      <td>0.11547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignore multiple problem</th>\n",
       "      <td>0.11547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immense momentum popular</th>\n",
       "      <td>0.11547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>important reason inability</th>\n",
       "      <td>0.11547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosmetic nothing us</th>\n",
       "      <td>0.11547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inability listen properly</th>\n",
       "      <td>0.11547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continue ignore multiple</th>\n",
       "      <td>0.11547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               score\n",
       "zone competitive world       0.11547\n",
       "properly organize community  0.11547\n",
       "hour come hard               0.11547\n",
       "real problem progress        0.11547\n",
       "ignore multiple problem      0.11547\n",
       "immense momentum popular     0.11547\n",
       "important reason inability   0.11547\n",
       "cosmetic nothing us          0.11547\n",
       "inability listen properly    0.11547\n",
       "continue ignore multiple     0.11547"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_lock = poor_review[poor_review['region_lock'] == True ]['final_text']\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3,3))\n",
    "X = vectorizer.fit_transform(region_lock)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "print(\"Top 10 Common theme related to region locking reviews with n-grams of 3\")\n",
    "score.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Common theme related to not worthy reviews with n-grams of 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pay mod fuck</th>\n",
       "      <td>5.016886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dont buy unless</th>\n",
       "      <td>3.867898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>club pay mod</th>\n",
       "      <td>3.513929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creation club pay</th>\n",
       "      <td>3.504164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay mod bad</th>\n",
       "      <td>3.421369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      score\n",
       "pay mod fuck       5.016886\n",
       "dont buy unless    3.867898\n",
       "club pay mod       3.513929\n",
       "creation club pay  3.504164\n",
       "pay mod bad        3.421369"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_worthy = poor_review[poor_review['not_worthy'] == True ]['final_text']\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3,3))\n",
    "X = vectorizer.fit_transform(not_worthy)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "print(\"Top 5 Common theme related to not worthy reviews with n-grams of 3\")\n",
    "score.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Common theme related to single player reviews with n-grams of 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_number_ year old</th>\n",
       "      <td>1.459696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy shark card</th>\n",
       "      <td>1.444074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ban use mod</th>\n",
       "      <td>1.195376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_number_ hour multiplayer</th>\n",
       "      <td>1.074287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ban singleplayer mod</th>\n",
       "      <td>1.071135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use mod singleplayer</th>\n",
       "      <td>1.037581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_number_ _number_ hour</th>\n",
       "      <td>1.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiplayer completely broken</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>singleplayer user though</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doom multiplayer horrible</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  score\n",
       "_number_ year old              1.459696\n",
       "buy shark card                 1.444074\n",
       "ban use mod                    1.195376\n",
       "_number_ hour multiplayer      1.074287\n",
       "ban singleplayer mod           1.071135\n",
       "use mod singleplayer           1.037581\n",
       "_number_ _number_ hour         1.003000\n",
       "multiplayer completely broken  1.000000\n",
       "singleplayer user though       1.000000\n",
       "doom multiplayer horrible      1.000000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_player = poor_review[poor_review['single_player'] == True ]['final_text']\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3,3))\n",
    "X = vectorizer.fit_transform(single_player)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "print(\"Top 10 Common theme related to single player reviews with n-grams of 3\")\n",
    "score.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Common theme related to game play experience reviews with n-grams of 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dlc early access</th>\n",
       "      <td>10.567972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay dlc early</th>\n",
       "      <td>5.232544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need lot work</th>\n",
       "      <td>4.182778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early access title</th>\n",
       "      <td>3.405531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy early access</th>\n",
       "      <td>3.262628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_number_ early access</th>\n",
       "      <td>2.886342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early access pay</th>\n",
       "      <td>2.810989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>access pay dlc</th>\n",
       "      <td>2.742918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buggy piece shit</th>\n",
       "      <td>2.738800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early access _number_</th>\n",
       "      <td>2.532354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           score\n",
       "dlc early access       10.567972\n",
       "pay dlc early           5.232544\n",
       "need lot work           4.182778\n",
       "early access title      3.405531\n",
       "buy early access        3.262628\n",
       "_number_ early access   2.886342\n",
       "early access pay        2.810989\n",
       "access pay dlc          2.742918\n",
       "buggy piece shit        2.738800\n",
       "early access _number_   2.532354"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_exp = poor_review[poor_review['game_exp'] == True ]['final_text']\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3,3))\n",
    "X = vectorizer.fit_transform(game_exp)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "print(\"Top 10 Common theme related to game play experience reviews with n-grams of 3\")\n",
    "score.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the above analysis, our team have identified some features that can help Steam generate more revenue in game contracts and also some areas for improvements. Users are generally sensitive about price. For some games, users think the game worth the money spent. However, there are also many games are not well-worthy according to the reviews. We recommend the opeartions, sales, and marketing team at Steam to complete further investments based on game type and region to determine if price reduction strategy or temporary promotion can be implemented. We also recommend these teams to perform target marketing based on users preferences' of single player mode or multiplayer mode. \n",
    "\n",
    "For game design team, users commented the most about game features and contents. A game is highly rated by users when the art style and story line are attractive. Users also enjoyed open world games, early access features, and turn based strategy. However, not all users are satisfied with their game play exprience. Some complained about in-game bugs and lags while some others complained about lacking of new game content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
