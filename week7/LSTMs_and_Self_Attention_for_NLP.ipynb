{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyO8h7loyUfr",
        "outputId": "71700b12-79b4-4f73-e66b-675d1e4d557e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dso-560-nlp-text-analytics'...\n",
            "remote: Enumerating objects: 3177, done.\u001b[K\n",
            "remote: Total 3177 (delta 0), reused 0 (delta 0), pack-reused 3177\u001b[K\n",
            "Receiving objects: 100% (3177/3177), 94.48 MiB | 18.46 MiB/s, done.\n",
            "Resolving deltas: 100% (394/394), done.\n",
            "Checking out files: 100% (3185/3185), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf dso-560-nlp-text-analytics && git clone https://github.com/ychennay/dso-560-nlp-text-analytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4G2F7OhyWLO",
        "outputId": "100e6624-f300-42d4-f740-a25d049d4066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dso-560-nlp-text-analytics\n"
          ]
        }
      ],
      "source": [
        "%cd dso-560-nlp-text-analytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e_ZBMG2x3Jh"
      },
      "source": [
        "# Attention and Transformers\n",
        "\n",
        "The original *Attention Is All You Need* paper is [available here](https://arxiv.org/pdf/1706.03762.pdf).\n",
        "\n",
        "The overall architecture of the **Transformer** model is defined here from the paper:\n",
        "![transformers](https://github.com/ychennay/dso-560-nlp-text-analytics/blob/main/images/transformers.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faWggRwOx3Jj"
      },
      "source": [
        "## Define Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2udDJPDCx3Jk"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 20000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qj31r5sCx3Jk"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Dense, LSTM, Flatten, concatenate, Activation, RepeatVector, Permute\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from random import randint\n",
        "from numpy import array, argmax, asarray, zeros\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "import numpy as np \n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm', disable=[\"pos\", \"ner\", \"tagger\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bstXqPxx3Jl"
      },
      "source": [
        "## Load in Amazon Reviews Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DepsWseLx3Jl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "NUM_SAMPLES = 2000\n",
        "\n",
        "good_reviews = open(\"datasets/good_amazon_toy_reviews.txt\").readlines()\n",
        "bad_reviews = open(\"datasets/poor_amazon_toy_reviews.txt\").readlines()\n",
        "\n",
        "sampled_good_reviews = good_reviews[:NUM_SAMPLES]\n",
        "sampled_bad_reviews = bad_reviews[:NUM_SAMPLES]\n",
        "\n",
        "docs = sampled_good_reviews + sampled_bad_reviews\n",
        "labels = np.concatenate([np.ones(NUM_SAMPLES), np.zeros(NUM_SAMPLES)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjhjLvJwx3Jm"
      },
      "source": [
        "## Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJyU3bQLx3Jm"
      },
      "outputs": [],
      "source": [
        "stopwords_removed_docs = list(\n",
        "    map(lambda doc: \" \".join([token.text for token in nlp(doc) if not token.is_stop]), docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi0vZNeyx3Jn"
      },
      "source": [
        "## Tokenize Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63ce6E3sx3Jn"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=10_000, oov_token=\"UNKNOWN_TOKEN\")\n",
        "tokenizer.fit_on_texts(stopwords_removed_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3bWcZ-Tx3Jn"
      },
      "source": [
        "## Integer Encode Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r31RJmcnx3Jo",
        "outputId": "f675c8c2-e11b-48fa-b877-56299d0d229a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length of sequences is 817\n"
          ]
        }
      ],
      "source": [
        "from typing import List\n",
        "def get_max_token_length_per_doc(docs: List[List[str]])-> int:\n",
        "    return max(list(map(lambda x: len(x.split()), docs)))\n",
        "\n",
        "# get the max length in terms of token length\n",
        "max_length = get_max_token_length_per_doc(docs)\n",
        "print(f\"Max length of sequences is {max_length}\")\n",
        "\n",
        "def integer_encode_documents(docs, tokenizer):\n",
        "    return tokenizer.texts_to_sequences(docs)\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "# integer encode the documents\n",
        "encoded_docs = integer_encode_documents(stopwords_removed_docs, tokenizer)\n",
        "# this is a list of lists, the numbers represent the index position of that word.\n",
        "# for instance, 33 means the 33rd word in the vocabulary\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxjBHlgex3Jo"
      },
      "source": [
        "## Load in GloVe Vectors\n",
        "Download the actual Glove vectors from S3 and unzip them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-irankP002no",
        "outputId": "4db2ee0a-6062-4ea9-8bc5-84e84b301bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-27 00:44:53--  https://dso-560-nlp-text-analytics.s3.amazonaws.com/glove6b100dtxt.zip\n",
            "Resolving dso-560-nlp-text-analytics.s3.amazonaws.com (dso-560-nlp-text-analytics.s3.amazonaws.com)... 54.231.113.251\n",
            "Connecting to dso-560-nlp-text-analytics.s3.amazonaws.com (dso-560-nlp-text-analytics.s3.amazonaws.com)|54.231.113.251|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 137847651 (131M) [application/zip]\n",
            "Saving to: ‘glove6b100dtxt.zip’\n",
            "\n",
            "glove6b100dtxt.zip  100%[===================>] 131.46M  33.7MB/s    in 4.5s    \n",
            "\n",
            "2022-04-27 00:44:58 (29.5 MB/s) - ‘glove6b100dtxt.zip’ saved [137847651/137847651]\n",
            "\n",
            "Archive:  glove6b100dtxt.zip\n",
            "  inflating: glove.6B.100d.txt       \n"
          ]
        }
      ],
      "source": [
        "!wget https://dso-560-nlp-text-analytics.s3.amazonaws.com/glove6b100dtxt.zip\n",
        "!unzip glove6b100dtxt.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dehu7nVDx3Jo",
        "outputId": "e34423fa-2fb5-4d57-e03f-3b4e080a8e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "def load_glove_vectors():\n",
        "    embeddings_index = {}\n",
        "    with open('glove.6B.100d.txt') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "    return embeddings_index\n",
        "\n",
        "\n",
        "embeddings_index = load_glove_vectors()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4rgGSm7x3Jp"
      },
      "source": [
        "## Load in Embeddings Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_Cig_7fx3Jp"
      },
      "outputs": [],
      "source": [
        "# create a weight matrix for words in training docs\n",
        "VOCAB_SIZE = 20_000\n",
        "embedding_matrix = np.zeros((VOCAB_SIZE, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWW0c0fJx3Jp"
      },
      "source": [
        "## Define an LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqbw-eyVx3Jp"
      },
      "outputs": [],
      "source": [
        "from keras.layers.recurrent import SimpleRNN, LSTM\n",
        "from keras.layers import Flatten, Masking\n",
        "from keras.layers import Embedding\n",
        "import keras\n",
        "def make_lstm_classification_model(plot=False, sequence_length = 100, vocab_size = 20000):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=sequence_length, trainable=False))\n",
        "    model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
        "    model.add(LSTM(units=64, input_shape=(1, sequence_length)))\n",
        "    model.add(Dense(16))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    # summarize the model\n",
        "    model.summary()\n",
        "    \n",
        "    if plot:\n",
        "        plot_model(model, to_file='model.png', show_shapes=True)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDuCukKxx3Jq"
      },
      "source": [
        "## Inside One LSTM Cell\n",
        "![LSTM](https://github.com/ychennay/dso-560-nlp-text-analytics/blob/main/images/lstm_architecture.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYP2QwWBx3Jq",
        "outputId": "f178346b-a340-4ccc-9221-32fe67601ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 100)          2000000   \n",
            "                                                                 \n",
            " masking (Masking)           (None, 100, 100)          0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                42240     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,043,297\n",
            "Trainable params: 43,297\n",
            "Non-trainable params: 2,000,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "lstm_model = make_lstm_classification_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jPabseIx3Jq"
      },
      "source": [
        "## Split Into Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiydCHB5x3Jq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_docs, labels, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--RAzQBM2UzZ"
      },
      "source": [
        "#### Train LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL8uWHVsx3Jq",
        "outputId": "4ed5ac1b-f3c1-470d-ec42-77575ebb7eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "113/113 [==============================] - 59s 459ms/step - loss: 0.4192 - accuracy: 0.8183 - val_loss: 0.3170 - val_accuracy: 0.8975\n",
            "Epoch 2/3\n",
            "113/113 [==============================] - 49s 438ms/step - loss: 0.2905 - accuracy: 0.8836 - val_loss: 0.3597 - val_accuracy: 0.8700\n",
            "Epoch 3/3\n",
            " 44/113 [==========>...................] - ETA: 29s - loss: 0.2562 - accuracy: 0.8949"
          ]
        }
      ],
      "source": [
        "# fit the model\n",
        "history = lstm_model.fit(padded_docs, labels, validation_split = 0.1, epochs=3, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lPqA0UPx3Jq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt # From https://keras.io/visualization/\n",
        "\n",
        "\n",
        "def plot_performance(history):\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "plot_performance(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij6xhycwx3Jq"
      },
      "source": [
        "# Ways to Improve Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izv5rpBvx3Jq"
      },
      "source": [
        "* **feature engineer** the text by grouping collocated tokens, removing stopwords, etc.\n",
        "\n",
        "* **use K-Folds cross-validation** to \"use\" more of the dataset in the training/validation/testing process.\n",
        "\n",
        "* **train your own custom domain-specific embeddings** (instead of using generic pre-trained ones)\n",
        "\n",
        "* **tune hyperparameters** - neural network architecture, activation functions, etc. \n",
        "\n",
        "* **enrich the data** using augmented datasets as features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdgrwORCx3Jq"
      },
      "source": [
        "## Self Attention Model\n",
        "\n",
        "Let's define a function to generate our self attention model. We'll install another library that augments Keras and creates self attention layers for us to use called `keras_self_attention` ([Github](https://pypi.org/project/keras-self-attention/))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVpr-4jKz7b9",
        "outputId": "9ecc1705-707e-4d9a-f100-f3d6e67298d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_self_attention\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_self_attention) (1.21.6)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18912 sha256=537140e782bc0f82ee0640d37b4bf6f91465b3769ae05e712c3449cae8015320\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/b1/a8/5ee00cc137940b2f6fa198212e8f45d813d0e0d9c3a04035a3\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.51.0\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_self_attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu7CCjbdx3Jq"
      },
      "outputs": [],
      "source": [
        "from keras_self_attention import SeqSelfAttention\n",
        "def make_self_attention_model(vocab_size=20_000, sequence_length = 100):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=sequence_length, trainable=False))\n",
        "    model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=300,\n",
        "                                                           return_sequences=True)))\n",
        "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "    model.add(keras.layers.Dense(units=1))\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'],\n",
        "    )\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8mVdHLpx3Jq"
      },
      "source": [
        "### Notes:\n",
        "\n",
        "Each LSTM has a hidden state and memory. You can ask `keras` to return the vectors that represent these sequences by using:\n",
        "\n",
        "#### Difference Between `return_sequences` and `return_states`\n",
        "\n",
        "```python\n",
        "LSTM(HIDDEN_STATE_DIMENSIONS, return_sequences=True)\n",
        "```\n",
        "\n",
        "If you had a `SEQUENCE_LENGTH` of **20**, and a `HIDDEN_STATE_DIMENSIONS` of **64**, then you'll produce a matrix of shape `64 x 20` as your `return_sequence`.\n",
        "\n",
        "On the other hand, `return_states` will return both the memory cells (`c`) as well as the hidden state `h`:\n",
        "\n",
        "```\n",
        "lstm, state_h, state_c = LSTM(..., return_state=True)\n",
        "```\n",
        "\n",
        "Here, `lstm` will be your LSTM model, `state_h` is your hidden state, and `state_c` is your cell memory state. \n",
        "\n",
        "Example from [Keras Returning Hidden State in RNNs](http://digital-thinking.de/keras-returning-hidden-state-in-rnns/):\n",
        "```\n",
        "inputs1 = Input(shape=(5, 1))\n",
        "lstm1, state_h, state_c = LSTM(1, return_state=True, return_sequences=True)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=[lstm1, state_h, state_c])\n",
        "data = array([0.1, 0.2, 0.3, 0.4, 0.5]).reshape((1,5,1))\n",
        "print(model.predict(data))\n",
        "```\n",
        "The output of this is\n",
        "```\n",
        "[array([[[0.00734747],\n",
        "        [0.02000349],\n",
        "        [0.03651035],\n",
        "        [0.05576567],\n",
        "        [0.07689518]]], dtype=float32), array([[0.07689518]], dtype=float32), array([[0.15496857]], dtype=float32)]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJvRF_gkx3Jr"
      },
      "source": [
        "## Model High-Level Architecture\n",
        "![architecture](https://github.com/ychennay/dso-560-nlp-text-analytics/blob/main/images/lstm_arch.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HynIzPQHx3Jr",
        "outputId": "855db4b6-9274-4e73-da83-3df3b42104e1",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 100, 100)          2000000   \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 100, 600)         962400    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " seq_self_attention_5 (SeqSe  (None, 100, 600)         38465     \n",
            " lfAttention)                                                    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 100, 1)            601       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,001,466\n",
            "Trainable params: 1,001,466\n",
            "Non-trainable params: 2,000,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "attention_model = make_self_attention_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRAxv6Fbx3Jr",
        "outputId": "d0de4085-5f05-4c75-9142-9b86350375db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "113/113 [==============================] - 8s 40ms/step - loss: 1.0213 - accuracy: 0.4962 - val_loss: 0.6415 - val_accuracy: 0.8314\n",
            "Epoch 2/5\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.7009 - accuracy: 0.5129 - val_loss: 0.6851 - val_accuracy: 0.5744\n",
            "Epoch 3/5\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6921 - accuracy: 0.5311 - val_loss: 0.8791 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6914 - accuracy: 0.5365 - val_loss: 0.8941 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/5\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.6917 - accuracy: 0.5406 - val_loss: 0.8507 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "attention_history = attention_model.fit(padded_docs, labels,validation_split = 0.1, epochs=5, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmd-XvNMx3Jr",
        "outputId": "ebefc089-ad70-4ba5-a75d-6212006caa2c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_performance(attention_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYqHy6Ofx3Jr",
        "outputId": "14fd34d5-bf3d-44aa-dc0d-8d74904c4589",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sequence length is 100.\n",
            "The input is of shape (3200, 100).\n",
            "The vocabulary size is 20000.\n",
            "The word embedding dimensions size is 100.\n",
            "The hidden state dimension size is 100.\n",
            "(20000, 100)\n",
            "(100, 1200)\n",
            "(300, 1200)\n",
            "(1200,)\n",
            "(100, 1200)\n",
            "(300, 1200)\n",
            "(1200,)\n",
            "(600, 32)\n",
            "(600, 32)\n",
            "(32,)\n",
            "(32, 1)\n",
            "(1,)\n",
            "(600, 1)\n",
            "(1,)\n"
          ]
        }
      ],
      "source": [
        "weights = attention_model.get_weights()\n",
        "print(f\"The sequence length is {MAX_SEQUENCE_LENGTH}.\")\n",
        "print(f\"The input is of shape {X_train.shape}.\")\n",
        "print(f\"The vocabulary size is {VOCAB_SIZE}.\")\n",
        "print(f\"The word embedding dimensions size is 100.\")\n",
        "print(f\"The hidden state dimension size is {MAX_SEQUENCE_LENGTH}.\")\n",
        "\n",
        "weight_purposes = [\"word_embeddings\", \n",
        "                   \"data_gate_weights\", \n",
        "                   \"hidden_state_gate_weights\",\n",
        "                   \"attention \"]\n",
        "\n",
        "for weights in attention_model.get_weights():\n",
        "    print(np.array(weights).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKIvTIrqx3Jr"
      },
      "source": [
        "# BERT (Bi-Directional Encoder Representations of Transformers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi-EkT3kx3Jr"
      },
      "source": [
        "## High Level Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw0xjEcCx3Jr"
      },
      "source": [
        "![bert](https://github.com/ychennay/dso-560-nlp-text-analytics/blob/main/images/bert_architecture.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfhtvVlPx3Jr"
      },
      "source": [
        "![comparison](https://github.com/ychennay/dso-560-nlp-text-analytics/blob/main/images/bert.webp?raw=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "LSTMs and Self-Attention for NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}