{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:43.066359Z",
     "start_time": "2022-04-27T02:09:43.063897Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6CCjYLpxhia",
    "outputId": "c0dcc5d9-8c81-4276-8e75-8dbd8a781bd9"
   },
   "outputs": [],
   "source": [
    "# !rm -rf dso-560-nlp-text-analytics && git clone https://github.com/ychennay/dso-560-nlp-text-analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:43.073021Z",
     "start_time": "2022-04-27T02:09:43.071346Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ely6wA-Fxloa",
    "outputId": "e6c019c6-281d-4765-bda8-c86c974a86bc"
   },
   "outputs": [],
   "source": [
    "# %cd dso-560-nlp-text-analytics/week5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DD32-zSlxgva"
   },
   "source": [
    "**Note: The following comes from [Use Word Embedding Layers - Deep Learning Keras](https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/).**\n",
    "# Training Your Own Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVcEbLhIxgvc"
   },
   "source": [
    "You'll need to make sure that `tensorflow` and `keras` are installed:\n",
    "```\n",
    "pip install tensorflow keras\n",
    "```\n",
    "\n",
    "### Note:\n",
    "The following is NOT implementing `word2vec`. It is simply training an embedding layer via a vanilla neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:45.299809Z",
     "start_time": "2022-04-27T02:09:43.075186Z"
    },
    "id": "3JA6x-d0xgvd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/antheayang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/antheayang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/antheayang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/antheayang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/antheayang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/antheayang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from numpy import asarray\n",
    "from numpy import array\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:45.306597Z",
     "start_time": "2022-04-27T02:09:45.303272Z"
    },
    "id": "fqNuaXICxgvd"
   },
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        \"Awesome job\",\n",
    "        \"Amazing\",\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good really bad',\n",
    "        'poor work',\n",
    "        \"Weak, not well done\",\n",
    "        'Poor job',\n",
    "        'Weak and terrible',\n",
    "        'Not very good',\n",
    "        'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0]) # 1 means it is positive, 0 means it is negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tdnt3k9xgve"
   },
   "source": [
    "## Define the Vocab Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:45.310763Z",
     "start_time": "2022-04-27T02:09:45.308380Z"
    },
    "id": "GM0pIV8ixgve"
   },
   "outputs": [],
   "source": [
    "# you set the vocabulary size to some number that represents the total number of unique words in your vocabulary\n",
    "vocab_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-danger\">\n",
    "recording</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BS1Iw6njMUlx"
   },
   "source": [
    "From the results of the `tokenizer.word_index`, we can see that `amazing` is the 11th position of the vocabulary. `done` is in index position 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:45.319635Z",
     "start_time": "2022-04-27T02:09:45.312105Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gk-aMpUZxgvf",
    "outputId": "57220315-b6fc-41c4-8295-907c66e2fe2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'done': 1,\n",
       " 'good': 2,\n",
       " 'work': 3,\n",
       " 'weak': 4,\n",
       " 'poor': 5,\n",
       " 'not': 6,\n",
       " 'well': 7,\n",
       " 'job': 8,\n",
       " 'effort': 9,\n",
       " 'awesome': 10,\n",
       " 'amazing': 11,\n",
       " 'great': 12,\n",
       " 'nice': 13,\n",
       " 'excellent': 14,\n",
       " 'really': 15,\n",
       " 'bad': 16,\n",
       " 'and': 17,\n",
       " 'terrible': 18,\n",
       " 'very': 19,\n",
       " 'could': 20,\n",
       " 'have': 21,\n",
       " 'better': 22}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(docs)\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iG6SiA8xgvg"
   },
   "source": [
    "## Integer Encode the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:45.324010Z",
     "start_time": "2022-04-27T02:09:45.321001Z"
    },
    "id": "OqA-Rvzsxgvg"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "def integer_encode_documents(docs: List[str], tokenizer: Tokenizer)-> List[List[int]]:\n",
    "    documents = []\n",
    "    for d in docs:\n",
    "        doc_integers = []\n",
    "        for i in text_to_word_sequence(d):\n",
    "            doc_integers.append(tokenizer.word_index[i])\n",
    "        documents.append(doc_integers)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:45.327684Z",
     "start_time": "2022-04-27T02:09:45.325260Z"
    },
    "id": "hK7Nndixxgvh"
   },
   "outputs": [],
   "source": [
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:45.341527Z",
     "start_time": "2022-04-27T02:09:45.337350Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELywu9aDxgvh",
    "outputId": "724ecfc8-d9a0-4bd6-b508-40842aa80215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7, 1],\n",
      " [2, 3],\n",
      " [10, 8],\n",
      " [11],\n",
      " [12, 9],\n",
      " [13, 3],\n",
      " [14],\n",
      " [4],\n",
      " [5, 9],\n",
      " [6, 2, 15, 16],\n",
      " [5, 3],\n",
      " [4, 6, 7, 1],\n",
      " [5, 8],\n",
      " [4, 17, 18],\n",
      " [6, 19, 2],\n",
      " [20, 21, 1, 22]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "encoded_docs = integer_encode_documents(docs, tokenizer)\n",
    "# this is a list of lists, the numbers represent the index position of that word.\n",
    "# for instance, 33 means the 33rd word in the vocabulary\n",
    "# Notice the last document has 4 numbers, since it is a 4 word document: Could have done better.\n",
    "from pprint import pprint\n",
    "pprint(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "'Could have done better.' -> [20, 21, 1, 22]</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLIM6Ldpxgvh"
   },
   "source": [
    "## Get Max Length of Documents\n",
    "\n",
    "We need to get the max length of our documents so we can define the sequence length for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:45.347082Z",
     "start_time": "2022-04-27T02:09:45.344974Z"
    },
    "id": "2BbnHSKHxgvh"
   },
   "outputs": [],
   "source": [
    "def get_max_token_length_per_doc(docs: List[str])-> int:\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:45.353759Z",
     "start_time": "2022-04-27T02:09:45.349006Z"
    },
    "id": "96kjB-Gd6bfU"
   },
   "outputs": [],
   "source": [
    "def get_max_token_length_per_doc(docs: List[str], tokenizer)-> int:\n",
    "    return max(list(map(lambda doc: len(doc), tokenizer.texts_to_sequences(docs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:45.358354Z",
     "start_time": "2022-04-27T02:09:45.355638Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uPFfYrxMxgvi",
    "outputId": "eab58029-0eed-4056-bf7d-5dd8c5fee99d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the max length in terms of token length\n",
    "max_length = get_max_token_length_per_doc(docs, tokenizer)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yg_G3zZpxgvi"
   },
   "source": [
    "## Pad Documents to Max Length\n",
    "Not all (in fact, most) of our documents will be of length `max_length`, so we need to pad their sequences so they become of length `max_length`. Here, since the max length is 4, we will extend each document sequence to length 4, using 0 to represent a padded token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:45.362702Z",
     "start_time": "2022-04-27T02:09:45.359720Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Daq3dtXKxgvi",
    "outputId": "0e6a8db7-a2d4-4945-a6f0-50fe4c756b29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded docs: [[ 7  1  0  0]\n",
      " [ 2  3  0  0]\n",
      " [10  8  0  0]\n",
      " [11  0  0  0]\n",
      " [12  9  0  0]\n",
      " [13  3  0  0]\n",
      " [14  0  0  0]\n",
      " [ 4  0  0  0]\n",
      " [ 5  9  0  0]\n",
      " [ 6  2 15 16]\n",
      " [ 5  3  0  0]\n",
      " [ 4  6  7  1]\n",
      " [ 5  8  0  0]\n",
      " [ 4 17 18  0]\n",
      " [ 6 19  2  0]\n",
      " [20 21  1 22]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(\"Padded docs:\", padded_docs)\n",
    "# since the max length is 4 words in a document, we pad all the documents to have 4 words, just set index to 0\n",
    "# if it doesn't have any words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKX7c01Kxgvi"
   },
   "source": [
    "After performing integer encoding and post padding, this will be what our dataset looks like:\n",
    "\n",
    "![Example](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/post_padding.png)\n",
    "\n",
    "Note: important design consideration - pad zeros after the document, or before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cfo0WAaaR5lo"
   },
   "source": [
    "### Mapping Our Document Into Embedded Representation\n",
    "\n",
    "We have convereted our text into tokens, our tokens into integer indices, and now we need to use our indices to look up the embeddings:\n",
    "![Example](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/embedding_lookup.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "convert doc into vectors</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijQupaY0xgvi"
   },
   "source": [
    "## Define an Embedding Size\n",
    "This represents how many numbers will \"represent\" a word. In `word2vec`, this would be 100, or 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:45.366825Z",
     "start_time": "2022-04-27T02:09:45.364153Z"
    },
    "id": "UCc-9YLexgvi"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9h9Lhd6xgvi"
   },
   "source": [
    "# Define Our Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:45.415743Z",
     "start_time": "2022-04-27T02:09:45.368119Z"
    },
    "id": "C-ThuTGJxgvj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/antheayang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "# remember, vocab_size = 50\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, EMBEDDING_SIZE, input_length=max_length))\n",
    "model.add(Flatten()) \n",
    "# for each document, the output of the embedding layer is 4 x 8 matrix\n",
    "# (4 since 4 words per document, 8 since size 8 embedding). Flatten makes this a 32 x 1 vector.\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "# these 32 elements are coalesced into one final output node, a sigmoid\n",
    "# that outputs a probability of positive or negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifbSIIXugIUr"
   },
   "source": [
    "![Architecture](https://camo.githubusercontent.com/f04ed71682d97610116589909f9cd4399d42c326e1bd57153ec9b9db4b409e3c/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f796368656e6e61792f64736f2d3536302d6e6c702d746578742d616e616c79746963732f6d61696e2f696d616765732f6172636869746563747572652e706e67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:45.465697Z",
     "start_time": "2022-04-27T02:09:45.417501Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5wP0Zyxmxgvj",
    "outputId": "e5d5320b-6f70-416d-bf97-ff60a6a3cb54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:45.469773Z",
     "start_time": "2022-04-27T02:09:45.467252Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNaA9CkkPPGU",
    "outputId": "76c87e35-dca7-4f50-abf3-4ed740c197a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:46.013106Z",
     "start_time": "2022-04-27T02:09:45.471549Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-XBCUTPGxgvj",
    "outputId": "292c4ff1-0691-4a0c-8746-6e7c0c8c71c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/antheayang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Accuracy: 87.500000\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "using the same training data here</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUwPzvZ7xgvj"
   },
   "source": [
    "### Get Embedding Layer Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:46.034466Z",
     "start_time": "2022-04-27T02:09:46.014788Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5teUcAMHRDZu",
    "outputId": "4d92d8e9-d91a-42de-e4d5-f8bff0d6d62f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:46.040699Z",
     "start_time": "2022-04-27T02:09:46.036112Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qjKllKf4xgvj",
    "outputId": "cc21dfdf-32bb-4df4-f6ae-e7fc174d66b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "embedding_layer.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "<i>embedding_layer[2, :]</i> is the embedded vec for <i>'good'</i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oK9VdlnCxgvj"
   },
   "source": [
    "## Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:46.048826Z",
     "start_time": "2022-04-27T02:09:46.044650Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNPxUaMOxgvj",
    "outputId": "953d530e-69c7-4c99-c914-092003feb94e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded docs: [[10  3  0  0]\n",
      " [15 16 18  0]\n",
      " [11  3  0  0]]\n"
     ]
    }
   ],
   "source": [
    "encoded_test_docs = integer_encode_documents([\"Awesome work\", \n",
    "                                              \"Really bad, terrible\", \n",
    "                                              \"amazing work\"], tokenizer)\n",
    "\n",
    "# pad test documents\n",
    "padded_test_docs = pad_sequences(encoded_test_docs, maxlen=max_length, padding='post')\n",
    "print(\"Padded docs:\", padded_test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:46.077271Z",
     "start_time": "2022-04-27T02:09:46.050804Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dAn8SvbDxgvj",
    "outputId": "19220b9c-2589-43aa-fdcd-519c032c2324"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59187865],\n",
       "       [0.4782587 ],\n",
       "       [0.59071434]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(padded_test_docs, verbose=0)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_K39rssxgvj"
   },
   "source": [
    "# Using Pre-Trained Embeddings\n",
    "\n",
    "We'll be using [pre-trained GloVe embeddings](https://nlp.stanford.edu/projects/glove/) for this example. These embeddings will have a dimension size of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:46.084497Z",
     "start_time": "2022-04-27T02:09:46.079349Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XHBZ2uCxgvj",
    "outputId": "d4963d36-e576-4723-b39a-6deefaf37503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded docs:\n",
      " [[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n",
      "Padded docs:\n",
      " [[ 6  2  0  0]\n",
      " [ 3  1  0  0]\n",
      " [ 7  4  0  0]\n",
      " [ 8  1  0  0]\n",
      " [ 9  0  0  0]\n",
      " [10  0  0  0]\n",
      " [ 5  4  0  0]\n",
      " [11  3  0  0]\n",
      " [ 5  1  0  0]\n",
      " [12 13  2 14]]\n"
     ]
    }
   ],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(\"Encoded docs:\\n\", encoded_docs)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(\"Padded docs:\\n\", padded_docs)\n",
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:46.087881Z",
     "start_time": "2022-04-27T02:09:46.086377Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TmiUPU_-yhdd",
    "outputId": "0f1a1711-da94-4ff0-cbb3-21fdde003b9b"
   },
   "outputs": [],
   "source": [
    "# !wget https://dso-560-nlp-text-analytics.s3.amazonaws.com/glove6b100dtxt.zip\n",
    "# !unzip glove6b100dtxt.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "6 billion docs, 100 dims</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:53.069056Z",
     "start_time": "2022-04-27T02:09:46.088897Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdx1gC4bxgvj",
    "outputId": "4fdfea47-34bf-45db-be01-c2d67089ca60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "f = open('../datasets/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4y2vaA0xgvj"
   },
   "source": [
    "## Pre-Load the Weight Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:53.075723Z",
     "start_time": "2022-04-27T02:09:53.070715Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yc43DTbKXDmL",
    "outputId": "c9a2f6a1-d620-48b3-de91-a9984a383a9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:53.089697Z",
     "start_time": "2022-04-27T02:09:53.082445Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:53.112657Z",
     "start_time": "2022-04-27T02:09:53.094100Z"
    },
    "id": "d9yp3G1qxgvj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 54070.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, i in tqdm(t.word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "GloVe embedding for happy:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:53.118796Z",
     "start_time": "2022-04-27T02:09:53.114508Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oPNyhDdhTX7s",
    "outputId": "38667147-9e40-4af7-c5b0-d3b859750518"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.090436 ,  0.19636  ,  0.29474  , -0.47706  , -0.80436  ,\n",
       "        0.3078   , -0.55205  ,  0.58453  , -0.17056  , -0.84846  ,\n",
       "        0.19528  ,  0.23671  ,  0.46827  , -0.58977  , -0.12163  ,\n",
       "       -0.24697  , -0.072944 ,  0.17259  , -0.0485   ,  0.9527   ,\n",
       "        0.50629  ,  0.58497  , -0.19367  , -0.45459  , -0.031095 ,\n",
       "        0.51633  , -0.24052  , -0.1007   ,  0.53627  ,  0.024225 ,\n",
       "       -0.50162  ,  0.73692  ,  0.49468  , -0.34744  ,  0.89337  ,\n",
       "        0.057439 , -0.19127  ,  0.39333  ,  0.21182  , -0.89837  ,\n",
       "        0.078704 , -0.16344  ,  0.45261  , -0.41096  , -0.19499  ,\n",
       "       -0.13489  , -0.016313 , -0.021849 ,  0.17136  , -1.2413   ,\n",
       "        0.079503 , -0.91144  ,  0.35699  ,  0.36289  , -0.24934  ,\n",
       "       -2.1196   ,  0.14534  ,  0.52964  ,  0.90134  ,  0.033603 ,\n",
       "        0.022809 ,  0.70625  , -1.0362   , -0.59809  ,  0.70592  ,\n",
       "       -0.072793 ,  0.67033  ,  0.52763  , -0.47807  , -0.67374  ,\n",
       "        0.36632  , -0.38284  , -0.10349  , -0.6402   ,  0.18104  ,\n",
       "        0.82568  ,  0.066403 , -0.40791  , -0.083813 , -0.36487  ,\n",
       "        0.045362 , -0.073527 , -0.20117  ,  0.37441  , -1.4024   ,\n",
       "       -0.25605  , -0.4708   , -0.16145  , -0.87921  , -0.36325  ,\n",
       "       -0.17357  , -0.077983 ,  0.43273  ,  0.0089295, -1.0316   ,\n",
       "       -0.11589  , -0.34524  ,  0.11514  , -0.40812  ,  0.20203  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"happy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:53.123439Z",
     "start_time": "2022-04-27T02:09:53.120431Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9Cn4oBSX9Lz",
    "outputId": "0d4fe19c-63f6-4fc0-9e22-6f1017148421"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:53.213641Z",
     "start_time": "2022-04-27T02:09:53.124771Z"
    },
    "id": "YO01aHXvxgvk"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "<i>trainable=False</i> 'cause pretrain GloVe</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:53.745966Z",
     "start_time": "2022-04-27T02:09:53.215067Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4-MYfqQxgvk",
    "outputId": "5194dcf7-d792-45f6-db1f-98148ebd56d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 4, 100)            1500      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 1,901\n",
      "Trainable params: 401\n",
      "Non-trainable params: 1,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:53.782641Z",
     "start_time": "2022-04-27T02:09:53.747174Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MBZVcp0Xxgvk",
    "outputId": "892966d3-1bd3-4e36-c395-1a67891d7bdf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56487656],\n",
       "       [0.768542  ],\n",
       "       [0.6842272 ],\n",
       "       [0.79415226],\n",
       "       [0.6176966 ],\n",
       "       [0.3246335 ],\n",
       "       [0.27925617],\n",
       "       [0.45349318],\n",
       "       [0.38107923],\n",
       "       [0.08172131]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:53.787425Z",
     "start_time": "2022-04-27T02:09:53.784234Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_o3dNVB6xgvk",
    "outputId": "f5b90699-4a57-42a0-d6c1-9e890379d909"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 2],\n",
       " [3, 1],\n",
       " [7, 4],\n",
       " [8, 1],\n",
       " [9],\n",
       " [10],\n",
       " [5, 4],\n",
       " [11, 3],\n",
       " [5, 1],\n",
       " [12, 13, 2, 14]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:53.790396Z",
     "start_time": "2022-04-27T02:09:53.788746Z"
    },
    "id": "8Eutt1Iixgvk"
   },
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:53.795433Z",
     "start_time": "2022-04-27T02:09:53.792142Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uYNCSD9wx9Nc",
    "outputId": "ec6f43ea-b58f-441a-bd56-8fc1a1a7345c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'work': 1,\n",
       " 'done': 2,\n",
       " 'good': 3,\n",
       " 'effort': 4,\n",
       " 'poor': 5,\n",
       " 'well': 6,\n",
       " 'great': 7,\n",
       " 'nice': 8,\n",
       " 'excellent': 9,\n",
       " 'weak': 10,\n",
       " 'not': 11,\n",
       " 'could': 12,\n",
       " 'have': 13,\n",
       " 'better': 14}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:53.802597Z",
     "start_time": "2022-04-27T02:09:53.796814Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KfPT2_Xrxgvk",
    "outputId": "243f67e2-39d5-43e9-cd28-1846f36bca19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded docs: [[ 5 10  4  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.12085503]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_test_docs = integer_encode_documents([\"Poor weak effort\"], t)\n",
    "\n",
    "# pad test documents\n",
    "padded_test_docs = pad_sequences(encoded_test_docs, maxlen=max_length, padding='post')\n",
    "print(\"Padded docs:\", padded_test_docs)\n",
    "model.predict(padded_test_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53FTTJi4xgvk"
   },
   "source": [
    "## Word Embeddings with Amazon Toy Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:53.873059Z",
     "start_time": "2022-04-27T02:09:53.803828Z"
    },
    "id": "gCBjs5L9xgvk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "NUM_SAMPLES = 5000\n",
    "\n",
    "good_reviews = open(\"../datasets/good_amazon_toy_reviews.txt\").readlines()\n",
    "bad_reviews = open(\"../datasets/poor_amazon_toy_reviews.txt\").readlines()\n",
    "\n",
    "sampled_good_reviews = good_reviews[:NUM_SAMPLES]\n",
    "sampled_bad_reviews = bad_reviews[:NUM_SAMPLES]\n",
    "\n",
    "docs = sampled_good_reviews + sampled_bad_reviews\n",
    "labels = np.concatenate([np.ones(NUM_SAMPLES), np.zeros(NUM_SAMPLES)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRvPLmzuxgvk"
   },
   "source": [
    "## Remove Stopwords Using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:10:42.061121Z",
     "start_time": "2022-04-27T02:09:53.874556Z"
    },
    "id": "hXBHt5Rsxgvk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antheayang/opt/anaconda3/lib/python3.7/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=[\"ner\", \"pos\", \"tagger\"])\n",
    "stopwords_removed_docs = list(\n",
    "    map(lambda doc: \" \".join([token.text for token in nlp(doc) if not token.is_stop]), docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQanzjnoxgvk"
   },
   "source": [
    "## Tokenize the Text\n",
    "I'm just using perhaps the most basic tokenization possible from Keras. Read [the documentation for more options](https://keras.io/preprocessing/text/). The most notable options:\n",
    "* `num_words`: the maximum number of words to keep, based on word frequency.\n",
    "* `oov_token`: adds a `OOB` (out of bag) or `OOV` (out of vocabulary) token to the `word_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:10:42.209932Z",
     "start_time": "2022-04-27T02:10:42.063313Z"
    },
    "id": "GoqG8Eecxgvk"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=500, oov_token=\"UNKNOWN_TOKEN\")\n",
    "tokenizer.fit_on_texts(stopwords_removed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:10:42.219297Z",
     "start_time": "2022-04-27T02:10:42.217228Z"
    },
    "id": "pnxbxUOwxgvk"
   },
   "outputs": [],
   "source": [
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:10:42.330403Z",
     "start_time": "2022-04-27T02:10:42.220878Z"
    },
    "id": "JNBei_Fzxgvk"
   },
   "outputs": [],
   "source": [
    "# integer encode the documents\n",
    "encoded_docs = integer_encode_documents(stopwords_removed_docs, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:10:42.799992Z",
     "start_time": "2022-04-27T02:10:42.331956Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "fb72jHWgPisT",
    "outputId": "cb4efbc8-5bff-4c9b-da06-72a26a5dae15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9.56e+03, 3.39e+02, 6.50e+01, 1.90e+01, 1.00e+01, 1.00e+00,\n",
       "        2.00e+00, 2.00e+00, 1.00e+00, 1.00e+00]),\n",
       " array([  0. ,  45.2,  90.4, 135.6, 180.8, 226. , 271.2, 316.4, 361.6,\n",
       "        406.8, 452. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.hist(list(map(lambda doc: len(doc), encoded_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:10:42.828043Z",
     "start_time": "2022-04-27T02:10:42.801129Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTFErccBOpBc",
    "outputId": "ef0c1afb-28d3-4d31-c9b4-b827a0cfc6df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[147,   0,   0, ...,   0,   0,   0],\n",
       "       [  3,  11,   1, ...,   0,   0,   0],\n",
       "       [ 29,  31, 496, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [ 22,   1,   5, ...,   0,   0,   0],\n",
       "       [ 77,   1, 125, ...,   0,   0,   0],\n",
       "       [293,   1,   0, ...,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 90\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:10:42.834370Z",
     "start_time": "2022-04-27T02:10:42.830681Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jej8VcnIxgvk",
    "outputId": "6f356e6a-4267-4fe1-8395-d25a3c1b0a82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size is 15951 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "vocab_size = int(len(tokenizer.word_index) * 1.3)\n",
    "print(f\"Vocab size is {vocab_size} unique tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:10:42.838395Z",
     "start_time": "2022-04-27T02:10:42.836525Z"
    },
    "id": "Gdm98_MRxgvk"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:10:42.841441Z",
     "start_time": "2022-04-27T02:10:42.839737Z"
    },
    "id": "oXXTlXoVxgvl"
   },
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvrdZPSaxgvl"
   },
   "source": [
    "# Define and Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:10:42.903828Z",
     "start_time": "2022-04-27T02:10:42.842601Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CCJ7yoCVxgvl",
    "outputId": "472f541c-635c-4329-c3e5-0a35d3eb88f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 90, 50)            797550    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4500)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 4501      \n",
      "=================================================================\n",
      "Total params: 802,051\n",
      "Trainable params: 802,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, EMBEDDING_SIZE, input_length=max_length))\n",
    "model.add(Flatten()) \n",
    "\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sv0bFAtyxgvl"
   },
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:15:28.096981Z",
     "start_time": "2022-04-27T02:10:42.906000Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8q4qKHKsxgvl",
    "outputId": "ed2598cd-972a-4632-a597-111b754a1dc7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 6s 612us/step - loss: 0.4738 - acc: 0.7772\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 6s 564us/step - loss: 0.2410 - acc: 0.9058\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.2088 - acc: 0.9169\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 6s 567us/step - loss: 0.1945 - acc: 0.9251\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 6s 554us/step - loss: 0.1843 - acc: 0.9265\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 9s 872us/step - loss: 0.1749 - acc: 0.9292\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 5s 535us/step - loss: 0.1663 - acc: 0.9342\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 5s 539us/step - loss: 0.1551 - acc: 0.9399\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.1454 - acc: 0.9455\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 5s 532us/step - loss: 0.1363 - acc: 0.9499\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 5s 545us/step - loss: 0.1270 - acc: 0.9528\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 6s 568us/step - loss: 0.1184 - acc: 0.9548\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 5s 548us/step - loss: 0.1104 - acc: 0.9585\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 6s 553us/step - loss: 0.1033 - acc: 0.9622\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 5s 535us/step - loss: 0.0970 - acc: 0.9638\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 5s 545us/step - loss: 0.0914 - acc: 0.9659\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 5s 542us/step - loss: 0.0863 - acc: 0.9696\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 6s 569us/step - loss: 0.0834 - acc: 0.9686\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 6s 599us/step - loss: 0.0787 - acc: 0.9703\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 6s 592us/step - loss: 0.0752 - acc: 0.9705\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 5s 538us/step - loss: 0.0719 - acc: 0.9739\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 5s 521us/step - loss: 0.0695 - acc: 0.9730\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 0.0679 - acc: 0.9740\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 5s 534us/step - loss: 0.0652 - acc: 0.9742\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 5s 543us/step - loss: 0.0636 - acc: 0.9744\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 5s 542us/step - loss: 0.0622 - acc: 0.9743\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 5s 537us/step - loss: 0.0600 - acc: 0.9740\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 5s 546us/step - loss: 0.0582 - acc: 0.9768\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 6s 558us/step - loss: 0.0568 - acc: 0.9774\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 6s 553us/step - loss: 0.0556 - acc: 0.9772\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 5s 539us/step - loss: 0.0544 - acc: 0.9769\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 6s 568us/step - loss: 0.0534 - acc: 0.9772\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 6s 561us/step - loss: 0.0524 - acc: 0.9780\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 10s 966us/step - loss: 0.0518 - acc: 0.9779\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 6s 578us/step - loss: 0.0513 - acc: 0.9775\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 6s 600us/step - loss: 0.0504 - acc: 0.9775\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 5s 549us/step - loss: 0.0498 - acc: 0.9787\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 6s 569us/step - loss: 0.0493 - acc: 0.9779\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 6s 552us/step - loss: 0.0485 - acc: 0.9788\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 6s 556us/step - loss: 0.0483 - acc: 0.9784\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 5s 537us/step - loss: 0.0479 - acc: 0.9786\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 0.0473 - acc: 0.9781\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 6s 554us/step - loss: 0.0472 - acc: 0.9778\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 6s 588us/step - loss: 0.0465 - acc: 0.9790\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 5s 550us/step - loss: 0.0464 - acc: 0.9776\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 5s 543us/step - loss: 0.0462 - acc: 0.9786\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 5s 547us/step - loss: 0.0458 - acc: 0.9786\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 5s 546us/step - loss: 0.0454 - acc: 0.9779\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 6s 582us/step - loss: 0.0452 - acc: 0.9781\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 5s 522us/step - loss: 0.0451 - acc: 0.9789\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "Accuracy: 97.939998\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=1)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:15:28.122552Z",
     "start_time": "2022-04-27T02:15:28.100610Z"
    },
    "id": "6B6wi3cPxgvl"
   },
   "outputs": [],
   "source": [
    "final_embeddings = model.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:15:28.127325Z",
     "start_time": "2022-04-27T02:15:28.123775Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r-h7hsPVxgvl",
    "outputId": "ec238295-27ad-4f5d-c2f1-726d76cb348e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15951, 50)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:15:28.447070Z",
     "start_time": "2022-04-27T02:15:28.128253Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTIiZhUlXJjp",
    "outputId": "a6755022-f437-4cc7-de7c-2e4dd76805bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00431442,  0.00170749,  0.00520867, ..., -0.0024768 ,\n",
       "         0.00154708,  0.0011879 ],\n",
       "       [-0.01810808, -0.12334399,  0.00766961, ..., -0.0562764 ,\n",
       "         0.01446077, -0.08724727],\n",
       "       [ 0.0009293 ,  0.3993408 ,  0.3986053 , ..., -0.11935483,\n",
       "        -0.00529255, -0.06079072],\n",
       "       ...,\n",
       "       [-0.00780251,  0.01092523, -0.04365399, ..., -0.02573267,\n",
       "        -0.00904896,  0.01962823],\n",
       "       [-0.03967545, -0.00916744,  0.0202576 , ...,  0.03327823,\n",
       "         0.01076112, -0.04911231],\n",
       "       [ 0.0228791 , -0.01821108, -0.02066082, ...,  0.01678339,\n",
       "         0.02161387,  0.02890401]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:15:28.450544Z",
     "start_time": "2022-04-27T02:15:28.448532Z"
    },
    "id": "F62AmEN5xgvl"
   },
   "outputs": [],
   "source": [
    "final_embeddings = final_embeddings[:len(tokenizer.word_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:15:28.457351Z",
     "start_time": "2022-04-27T02:15:28.452509Z"
    },
    "id": "VexY67xBxgvl"
   },
   "outputs": [],
   "source": [
    "embeddings_dict = {token: embedding for token, embedding in zip(tokenizer.word_index, final_embeddings)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWlTkXptxgvl"
   },
   "source": [
    "# Find Similarities of the new Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:15:29.236682Z",
     "start_time": "2022-04-27T02:15:28.458442Z"
    },
    "id": "QPceDfVuxgvl"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:15:29.831134Z",
     "start_time": "2022-04-27T02:15:29.238005Z"
    },
    "id": "5k3dptKxxgvl"
   },
   "outputs": [],
   "source": [
    "similarities = pd.DataFrame(cosine_similarity(final_embeddings), \n",
    "                            index=tokenizer.word_index, columns=tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:16:01.110544Z",
     "start_time": "2022-04-27T02:15:29.832523Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UGscWrPuxgvl",
    "outputId": "70783514-88c7-4adb-f53e-dd74b5daf72a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150540630, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unstack matrix into table\n",
    "similarity_table = similarities.rename_axis(None).rename_axis(None, axis=1).stack().reset_index()\n",
    "# rename columns\n",
    "similarity_table.columns = [\"word1\", \"word2\", \"similarity\"]\n",
    "similarity_table.shape\n",
    "\n",
    "similarity_table = similarity_table[similarity_table[\"similarity\"] < 0.99]\n",
    "similarity_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:16:01.414153Z",
     "start_time": "2022-04-27T02:16:01.112660Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "mXy8O9IvWZoX",
    "outputId": "b8a5b69a-28c4-4a17-98e6-2047adb9d72f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1926643</th>\n",
       "      <td>7</td>\n",
       "      <td>girl</td>\n",
       "      <td>0.944572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104467</th>\n",
       "      <td>girl</td>\n",
       "      <td>7</td>\n",
       "      <td>0.944572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227398</th>\n",
       "      <td>favorite</td>\n",
       "      <td>close</td>\n",
       "      <td>0.934612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4761023</th>\n",
       "      <td>close</td>\n",
       "      <td>favorite</td>\n",
       "      <td>0.934612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word1     word2  similarity\n",
       "1926643         7      girl    0.944572\n",
       "3104467      girl         7    0.944572\n",
       "3227398  favorite     close    0.934612\n",
       "4761023     close  favorite    0.934612"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_table[similarity_table[\"similarity\"] > 0.93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:17:40.073665Z",
     "start_time": "2022-04-27T02:16:01.415616Z"
    },
    "id": "eRvPL3P5xgvl"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1926643</th>\n",
       "      <td>7</td>\n",
       "      <td>girl</td>\n",
       "      <td>0.944572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4761023</th>\n",
       "      <td>close</td>\n",
       "      <td>favorite</td>\n",
       "      <td>0.934612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37063</th>\n",
       "      <td>34</td>\n",
       "      <td>girl</td>\n",
       "      <td>0.929279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607479</th>\n",
       "      <td>days</td>\n",
       "      <td>fast</td>\n",
       "      <td>0.926517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442055</th>\n",
       "      <td>perfect</td>\n",
       "      <td>balloon</td>\n",
       "      <td>0.926319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705910</th>\n",
       "      <td>guess</td>\n",
       "      <td>wood</td>\n",
       "      <td>0.921322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086346</th>\n",
       "      <td>'</td>\n",
       "      <td>00</td>\n",
       "      <td>0.921253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607633</th>\n",
       "      <td>days</td>\n",
       "      <td>favorite</td>\n",
       "      <td>0.920241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380376</th>\n",
       "      <td>set</td>\n",
       "      <td>product</td>\n",
       "      <td>0.918839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539943</th>\n",
       "      <td>5</td>\n",
       "      <td>water</td>\n",
       "      <td>0.917412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086009</th>\n",
       "      <td>'</td>\n",
       "      <td>fast</td>\n",
       "      <td>0.915686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337693</th>\n",
       "      <td>fast</td>\n",
       "      <td>favorite</td>\n",
       "      <td>0.914629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337466</th>\n",
       "      <td>fast</td>\n",
       "      <td>perfect</td>\n",
       "      <td>0.913275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441851</th>\n",
       "      <td>perfect</td>\n",
       "      <td>days</td>\n",
       "      <td>0.912568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926436</th>\n",
       "      <td>15</td>\n",
       "      <td>perfect</td>\n",
       "      <td>0.912532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4540342</th>\n",
       "      <td>wood</td>\n",
       "      <td>exchange</td>\n",
       "      <td>0.912206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515774</th>\n",
       "      <td>gift</td>\n",
       "      <td>packs</td>\n",
       "      <td>0.910587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37159</th>\n",
       "      <td>34</td>\n",
       "      <td>overall</td>\n",
       "      <td>0.909135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5754834</th>\n",
       "      <td>100</td>\n",
       "      <td>wish</td>\n",
       "      <td>0.907056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306930</th>\n",
       "      <td>kid</td>\n",
       "      <td>'</td>\n",
       "      <td>0.906451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626103</th>\n",
       "      <td>replacement</td>\n",
       "      <td>products</td>\n",
       "      <td>0.906437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423510</th>\n",
       "      <td>exchange</td>\n",
       "      <td>'</td>\n",
       "      <td>0.906071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926486</th>\n",
       "      <td>7</td>\n",
       "      <td>batteries</td>\n",
       "      <td>0.905565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110620</th>\n",
       "      <td>balloon</td>\n",
       "      <td>'</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4540070</th>\n",
       "      <td>wood</td>\n",
       "      <td>'</td>\n",
       "      <td>0.904627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558326</th>\n",
       "      <td>balloons</td>\n",
       "      <td>perfect</td>\n",
       "      <td>0.904482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214871</th>\n",
       "      <td>poorly</td>\n",
       "      <td>days</td>\n",
       "      <td>0.904230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282483</th>\n",
       "      <td>overall</td>\n",
       "      <td>girl</td>\n",
       "      <td>0.903745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926588</th>\n",
       "      <td>15</td>\n",
       "      <td>kid</td>\n",
       "      <td>0.903513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110581</th>\n",
       "      <td>balloon</td>\n",
       "      <td>days</td>\n",
       "      <td>0.903420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word1      word2  similarity\n",
       "1926643            7       girl    0.944572\n",
       "4761023        close   favorite    0.934612\n",
       "37063             34       girl    0.929279\n",
       "1607479         days       fast    0.926517\n",
       "442055       perfect    balloon    0.926319\n",
       "3705910        guess       wood    0.921322\n",
       "2086346            '         00    0.921253\n",
       "1607633         days   favorite    0.920241\n",
       "380376           set    product    0.918839\n",
       "539943             5      water    0.917412\n",
       "2086009            '       fast    0.915686\n",
       "1337693         fast   favorite    0.914629\n",
       "1337466         fast    perfect    0.913275\n",
       "441851       perfect       days    0.912568\n",
       "3926436           15    perfect    0.912532\n",
       "4540342         wood   exchange    0.912206\n",
       "515774          gift      packs    0.910587\n",
       "37159             34    overall    0.909135\n",
       "5754834          100       wish    0.907056\n",
       "2306930          kid          '    0.906451\n",
       "2626103  replacement   products    0.906437\n",
       "5423510     exchange          '    0.906071\n",
       "1926486            7  batteries    0.905565\n",
       "4110620      balloon          '    0.904687\n",
       "4540070         wood          '    0.904627\n",
       "1558326     balloons    perfect    0.904482\n",
       "3214871       poorly       days    0.904230\n",
       "4282483      overall       girl    0.903745\n",
       "3926588           15        kid    0.903513\n",
       "4110581      balloon       days    0.903420"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_table.sort_values(by=\"similarity\", ascending=False).drop_duplicates(\n",
    "    subset=\"similarity\", keep=\"first\").head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBD3XyExUCZ8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": " Deep Learning with Word Embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.796875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
