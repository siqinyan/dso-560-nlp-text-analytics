{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcstbTSixEC7"
   },
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "import spacy\n",
    "from scipy.spatial.distance import cosine\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "xk7jUQwSxEC6"
   },
   "source": [
    "# Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "M-hfEskTxEC6"
   },
   "source": [
    "## Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "hidden": true,
    "id": "JKFIitOhxEC7",
    "outputId": "1e0ea55a-fe12-426a-d8d7-b1cbef568b00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-46ef5827-a379-4a19-8348-3c92eb558b17\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>tag</th>\n",
       "      <th>dependency</th>\n",
       "      <th>shape</th>\n",
       "      <th>is_alphanumeric</th>\n",
       "      <th>is_stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steve</td>\n",
       "      <td>Steve</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jobs</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>cc</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>conj</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>aux</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46ef5827-a379-4a19-8348-3c92eb558b17')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-46ef5827-a379-4a19-8348-3c92eb558b17 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-46ef5827-a379-4a19-8348-3c92eb558b17');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    text  lemma part_of_speech  tag dependency  shape  is_alphanumeric  \\\n",
       "0  Steve  Steve          PROPN  NNP   compound  Xxxxx             True   \n",
       "1   Jobs   Jobs          PROPN  NNP      nsubj   Xxxx             True   \n",
       "2    and    and          CCONJ   CC         cc    xxx             True   \n",
       "3  Apple  Apple          PROPN  NNP       conj  Xxxxx             True   \n",
       "4     is     be            AUX  VBZ        aux     xx             True   \n",
       "\n",
       "   is_stopword  \n",
       "0        False  \n",
       "1        False  \n",
       "2         True  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "rows = []\n",
    "doc = nlp(u\"Steve Jobs and Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    rows.append((token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop))\n",
    "    \n",
    "data = pd.DataFrame(rows, columns=[\"text\", \"lemma\", \"part_of_speech\", \"tag\", \"dependency\", \"shape\", \"is_alphanumeric\", \"is_stopword\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "hmXlc4MjxEC7"
   },
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "nsFVbvwpxEC7",
    "outputId": "07f8cf20-2167-4af0-e152-e9e8404d4af3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steve Jobs 0 10 PERSON\n",
      "Apple 15 20 ORG\n",
      "U.K. 42 46 GPE\n",
      "$1 billion 59 69 MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Steve Jobs and Apple is looking at buying U.K. startup for $1 billion\")\n",
    "import en_core_web_sm\n",
    "import spacy\n",
    "from scipy.spatial.distance import cosine\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "jDFgMyZLxEC8"
   },
   "outputs": [],
   "source": [
    "# visualize this using displacy:\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwidJzngxEC_"
   },
   "source": [
    "# Embedding Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6sDh5qaWpIy",
    "outputId": "3f9cd8ae-818d-45ad-fe52-759277c4e153"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.0170894 , -1.5468277 ,  1.4642837 , -0.45664647,  2.416998  ,\n",
       "       -0.82837516,  0.773814  ,  0.7099814 ,  0.73783636,  1.9741133 ,\n",
       "        3.7342863 ,  2.0679865 ,  3.8942056 , -0.6749698 ,  0.37507713,\n",
       "       -2.0970044 , -0.6250715 ,  2.6508548 , -1.5724103 , -4.0325656 ,\n",
       "       -1.4097672 ,  0.39648557, -0.70805675, -1.0381888 ,  1.6989393 ,\n",
       "       -1.0706389 ,  0.66801304, -3.9096825 ,  2.607851  , -0.7741172 ,\n",
       "        3.8687487 , -0.28618616,  0.40867335,  2.0196295 , -0.8187747 ,\n",
       "       -1.3746587 ,  1.1600451 , -0.06880021, -1.3988796 ,  0.5209464 ,\n",
       "        4.9956036 ,  2.896077  ,  0.08491665, -3.1742032 ,  0.00753534,\n",
       "        1.8921385 , -0.12929648,  0.30110502, -0.8420582 , -0.76468706,\n",
       "        0.44588238, -1.4486729 , -2.1735194 , -0.56612396, -1.6122862 ,\n",
       "        0.677354  ,  3.816813  , -1.1397399 ,  0.25616455, -1.4188657 ,\n",
       "        0.62450516,  0.42642492, -1.1126095 , -1.6981561 ,  0.53187704,\n",
       "       -3.6243727 ,  1.3320243 , -0.53186584, -4.1490126 ,  0.51309955,\n",
       "       -1.7622366 ,  0.27966785,  3.2404723 ,  4.020842  , -2.5674777 ,\n",
       "       -1.8821824 , -1.6171422 , -0.24784362, -2.0150647 ,  2.2082977 ,\n",
       "       -0.87220526, -1.7021657 , -2.7035434 , -1.5503719 ,  0.16437384,\n",
       "        4.456564  , -0.7342907 , -0.97519994, -0.30850434, -4.1527653 ,\n",
       "       -1.9670217 ,  1.7923    , -1.7810124 ,  2.9184368 ,  0.6264006 ,\n",
       "        0.8974809 ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('dog').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "G2xYuDOaxEC_",
    "outputId": "4ecc628b-ebfe-4e40-c4ac-0e0a9b981e10"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2103: FutureWarning: The `axis` variable is no longer used and will be removed. Instead, assign variables directly to `x` or `y`.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "vector = nlp(u'banana').vector\n",
    "\n",
    "ax = sns.distplot(vector, kde=False, rug=True)\n",
    "t = ax.set_title('Histogram of Feature Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_j3a5DywXDG6",
    "outputId": "8d653b24-62fa-4d21-9c95-d03b9b15bfe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058947247"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "centered at 0, bell curve shaped, a little biased</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pbKGNmrxEC_"
   },
   "source": [
    "## Optimization Techniques\n",
    "\n",
    "### Subsampling\n",
    "\n",
    "What do we do with highly frequent words like `the` or `of`? We don't gain a ton of meaning from training on these words, and they become computationally expensive since they appear so frequently:\n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/subsampling.png \"http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/\")\n",
    "In the image above, $z(w_i)$ is the frequency of that particular word divided by the total number of words in the entire corpus. For instance, if a corpus of text has 50 words, and the word `dog` appears 3 times, $z(w_{dog}) = 0.06$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "XbnY0dfzxEC_",
    "outputId": "da4f4811-8152-4953-8897-c7ee4737abe9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# write subsampling function\n",
    "def subsample(z):\n",
    "    return ((z * 1000) ** 0.5 + 1) * (0.001 / z)\n",
    "\n",
    "# plot this function:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Z = list(np.linspace(0,1,100))\n",
    "probability_of_keeping = list(map( lambda z: subsample(z), Z))\n",
    "\n",
    "plt.scatter(Z, probability_of_keeping)\n",
    "plt.xlabel(\"Frequency word appears in corpus\")\n",
    "plt.ylabel(\"Probability of keeping\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nV5ojBE2xEC_"
   },
   "source": [
    "## Limitations of Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "<p><b>cons of word2vec:</b>\n",
    "<p>(1) out of vocabulary words, 'cause it's static\n",
    "<p>(2) does not deal with polysemy (i.e. words w/ multiple meanings)\n",
    "<p>(3) cannot handle antonym (i.e. opposite meaning) well e.g. turn left/right\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "<p>word embeddings - 10+ yrs old, not modern\n",
    "<p>while self-attention conduct embeddings within context</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nV5ojBE2xEC_"
   },
   "source": [
    "#### How to handle **Out Of Vocabulary (OOV)** words?\n",
    "Although **word2vec** and **FastText** include a significant vocabulary size, there will inevitably be words that are not included. For instance, if you are analyzing text conversations using word embeddings pretrained on Wikipedia text (which typically has more formal vocabulary than everyday language), how will you account for the following words?\n",
    "\n",
    "- DM\n",
    "- ROFLMAO\n",
    "- bae\n",
    "- ðŸ˜ƒ\n",
    "- #10YearChallenge\n",
    "- wut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nV5ojBE2xEC_"
   },
   "source": [
    "#### Potential solution: use word embeddings if they are available, and otherwise initialize the weights to random.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "def vectorize_word(input_word: str, D=50):\n",
    "    \"\"\"\n",
    "    D: an integer that represents the length (dimensionality of the word embeddings)\n",
    "    word_embeddings: A dictionary object with the string word as the key, and the embedding vector of \n",
    "    length D as the values.\n",
    "    For instance, word_embeddings[\"cat\"] will return [2.3, 4.5, 6.1, -2.2, ...]\n",
    "    \"\"\"\n",
    "    if input_word in word_embeddings.keys():\n",
    "        return word_embeddings[input_word]\n",
    "    else:\n",
    "        return np.random.rand(D)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "<p>'cause word2vec is static, re-train model is costly, thus we could train model for certain domains, e.g. BERT for law\n",
    "<p>thus may generate random number for OOV words, or maybe np.zeros, which is bad for backpropagation</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nV5ojBE2xEC_"
   },
   "source": [
    "##### Should we update the word embedding matrices during the model training step?\n",
    "- Ideally, you'd only want to be able to update the specific weights that were randomly initialized (since the rest of the weights are by definition pre-trained and are already pretty good). However, most deep learning libraries do not allow you to easily select which specific weight elements to apply backpropagation to- you either update all weights or you update none. In practice, most data scientists will \"freeze\" the word embedding layer:\n",
    "\n",
    "In Keras:\n",
    "```python\n",
    "word_embedding_layer.trainable = False # by default, trainable is set to true in Keras\n",
    "```\n",
    "In Tensorflow:\n",
    "```python\n",
    "import tensorflow as tf\n",
    "N = 300 # number of words\n",
    "D = 50 # of dimensions in embeddings\n",
    "initial_word_embeddings = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "tensor = tf.constant(initial_word_embeddings, shape=[N, D])\n",
    "```\n",
    "\n",
    "- Ambiguity around **Domain-specific words**: using a generic pre-trained word embedding will not capture the semantic meaning of the word **sack** when it is used in the context of American football:\n",
    "![sack](https://github.com/ychennay/dso-560-nlp-text-analytics/blob/main/images/football-bag-sack-diff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "PGPrMRVVxEC_"
   },
   "source": [
    "# Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "IM-cGru-xEC_"
   },
   "outputs": [],
   "source": [
    "# from https://radimrehurek.com/gensim/models/word2vec.html\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "path = get_tmpfile(\"word2vec.model\")\n",
    "model = Word2Vec(common_texts, window=5, min_count=1, workers=4)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "5hPNDy4jxEC_",
    "outputId": "13c268d2-c8be-4fca-9669-8c1f4716ff86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "YOCZ1SXFxEC_",
    "outputId": "081a0935-fa5e-4a76-8768-3c57d567b4c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=7, size=100, alpha=0.025)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.54153623e-03, -3.48760281e-04,  5.30791294e-04, -2.03038449e-03,\n",
       "        2.47618358e-04, -2.72349105e-03, -4.15661931e-03,  2.79788417e-03,\n",
       "       -1.51605392e-03,  1.86079473e-04, -3.11617088e-03,  1.11755601e-03,\n",
       "        3.02301859e-03,  4.43327567e-03, -2.63661123e-03,  2.94935261e-03,\n",
       "        3.09907855e-03, -2.41916534e-03, -4.75868955e-03,  1.20391056e-03,\n",
       "        8.75944505e-04, -8.18667759e-04, -1.94890914e-03, -4.99379530e-04,\n",
       "       -1.95534108e-03,  1.09112146e-03, -4.99140657e-03,  9.19170736e-04,\n",
       "       -2.84165633e-03, -1.55849801e-03,  3.07720038e-03,  3.18907946e-03,\n",
       "        3.29773012e-03,  3.79594835e-03, -2.71949009e-03, -2.58724554e-03,\n",
       "        3.99028091e-03,  6.67706074e-04,  1.37356203e-03, -4.82187932e-03,\n",
       "       -2.57848715e-03,  6.39133446e-04,  2.46286346e-03,  7.04145932e-04,\n",
       "       -4.86483751e-03, -2.28525302e-03,  2.37685163e-03, -3.31575837e-04,\n",
       "        3.82146356e-03,  4.91210539e-03, -2.18449603e-03,  3.76164052e-03,\n",
       "        7.91351951e-04, -1.48491724e-03, -1.90423802e-03, -3.70607292e-03,\n",
       "        2.76179332e-03, -4.89739049e-03,  2.59581301e-03,  4.67030419e-04,\n",
       "        3.75799625e-03,  2.32935953e-03, -4.34964243e-03, -4.38323617e-03,\n",
       "        3.65963113e-03, -1.16620446e-03,  1.65663587e-04, -3.65171302e-03,\n",
       "       -1.20548495e-04, -4.58783470e-03, -4.38050041e-03, -3.82865802e-03,\n",
       "        4.90083126e-03, -1.11365596e-04, -1.86647160e-03, -1.65055855e-04,\n",
       "        4.10342065e-04,  2.51507387e-03, -4.96854447e-03,  5.56469149e-06,\n",
       "       -4.86575626e-03, -1.42919365e-03,  1.59189373e-03,  1.57387811e-03,\n",
       "       -3.66804493e-03,  4.04581340e-04, -1.72022672e-03,  2.97708460e-03,\n",
       "       -4.90573095e-03,  5.19317866e-04, -2.78581306e-03, -1.91463286e-03,\n",
       "       -6.32304989e-04, -4.85963392e-04, -3.31696309e-03,  2.83500087e-03,\n",
       "        4.66040755e-03, -3.45114851e-03, -4.76377364e-03, -3.70798371e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# define training data\n",
    "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
    "             ['this', 'is', 'the', 'second', 'sentence'],\n",
    "             ['yet', 'another', 'sentence'],\n",
    "             ['one', 'more', 'sentence'],\n",
    "             ['and', 'the', 'final', 'sentence'],\n",
    "            [\"first\", \"and\", \"second\", \"sentence\"]]\n",
    "# train model\n",
    "# you can also specify an alpha, which is a hyperparameter learning rate\n",
    "model = Word2Vec(sentences, min_count=2)\n",
    "# summarize the loaded model\n",
    "print(model)\n",
    "# summarize vocabulary1\n",
    "model.wv.get_vector(\"sentence\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "vPr8x6SuxEC_"
   },
   "source": [
    "## Training Your Own Word2Vec Embeddings Using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "X1zAmWc1xEC_"
   },
   "outputs": [],
   "source": [
    "reviews = open(\"datasets/good_amazon_toy_reviews.txt\").readlines() + open(\"datasets/poor_amazon_toy_reviews.txt\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "aMFM5u5dxEDA",
    "outputId": "b9104db7-8666-40b1-e673-ee28ef9fcc89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "9PY2q64qxEDA"
   },
   "outputs": [],
   "source": [
    "docs = [word_tokenize(review) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "5lZmKY6pxEDA"
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(docs, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "G6Wgw6FWxEDA",
    "outputId": "b53110c3-5abf-45be-a231-45d8f0c5fa5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Amazon', 0.8636035919189453),\n",
       " ('sale', 0.7818915247917175),\n",
       " ('whim', 0.635441780090332),\n",
       " ('eBay', 0.6243037581443787),\n",
       " ('date', 0.6104319095611572),\n",
       " ('here', 0.6057115197181702),\n",
       " ('mine', 0.593768298625946),\n",
       " ('Prime', 0.5793049335479736),\n",
       " ('ebay', 0.5731858611106873),\n",
       " ('site', 0.5666931867599487)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"amazon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "7DqdreLlxEDA"
   },
   "source": [
    "## Using GoogleNews word2vec vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "VXSbcfyYxEDA"
   },
   "outputs": [],
   "source": [
    "# load in the entire Google News word embedding vectors\n",
    "from gensim.models import KeyedVectors\n",
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)\n",
    "\n",
    "# word analogies\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Ev9TSdjrxEDA"
   },
   "outputs": [],
   "source": [
    "# get the most similar words for a target word\n",
    "model.most_similar(\"cappucino\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "8OXEZ3qxxEDA"
   },
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "R7ScfqnGxEDA"
   },
   "source": [
    "A major problem with `word2vec` and other traditional word embedding strategies is how to deal with out of bag (OOB) or out of vocabulary (OOV) words.\n",
    "\n",
    "The vector embedding for the word `photosynthesis` will be the average of `pho`, `phot`, `photo`, etc.\n",
    "\n",
    "This allow FastText to embed many words that are not traditionally in the trained vocabulary (`photogenic` may be OOB, but `photo` will be available).\n",
    "\n",
    "### When to use?\n",
    "\n",
    "- traditionally, each individual word is trained onto a new word embedding\n",
    "- in many languages (including English), many words are morphologically derivative from each other. \n",
    "- use case when your corpus contains high-value, morphologically diverse, rare words (`photosynthesis`, `transcendentalism`)\n",
    "- may also be effective when your text contains lots of misspellings or abbreviations (ie. SMS, digital conversations)\n",
    "\n",
    "#### How is it Different Than word2vec?\n",
    "\n",
    "- word2vec considers only the entire word, whereas `fasttext` will consider each suffix n-gram.\n",
    "\n",
    "As [Radim Hurek](https://radimrehurek.com/gensim/auto_examples/tutorials/run_fasttext.html) says:\n",
    "\n",
    "> The main principle behind fastText is that the morphological structure of a word carries important information about the meaning of the word. Such structure is not taken into account by traditional word embeddings like Word2Vec, which train a unique word embedding for every individual word. This is especially significant for morphologically rich languages (German, Turkish) in which a single word can have a large number of morphological forms, each of which might occur rarely, thus making it hard to train good word embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "T68omdZAxEDA"
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "model = fasttext.train_unsupervised(\n",
    "    '../week1/good_amazon_toy_reviews.txt', model='skipgram', lr=0.05, dim=100, ws=5, epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "0BiLizyKxEDA"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(model[\"adore\"].reshape(1,-1), model[\"love\"].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "UPvoExfzxEDA"
   },
   "source": [
    "### FastText Hyperparameters (From [Tutorial Notebook](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb))\n",
    "- **model**: Training architecture. Allowed values: `cbow`, `skipgram` (Default `cbow`)\n",
    "- **size**: Size of embeddings to be learnt (Default 100)\n",
    "- **alpha**: Initial learning rate (Default 0.025)\n",
    "- **window**: Context window size (Default 5)\n",
    "- **min_count**: Ignore words with number of occurrences below this (Default 5)\n",
    "- **loss**: Training objective. Allowed values: `ns`, `hs`, `softmax` (Default `ns`)\n",
    "- **sample**: Threshold for downsampling higher-frequency words (Default 0.001)\n",
    "- **negative**: Number of negative words to sample, for `ns` (Default 5)\n",
    "- **iter**: Number of epochs (Default 5)\n",
    "- **sorted_vocab**: Sort vocab by descending frequency (Default 1)\n",
    "- **threads**: Number of threads to use (Default 12)\n",
    "\n",
    "Hyperparameters unique to `fasttext`:\n",
    "- **min_n**: min length of char ngrams (Default 3)\n",
    "- **max_n**: max length of char ngrams (Default 6)\n",
    "- **bucket**: number of buckets used for hashing ngrams (Default 2000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "XiAIX6hexEDA"
   },
   "source": [
    "## Gensim Implementation of FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "T1zz3OF8xEDA"
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "CrwDJOTnxEDA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "text = list(pd.read_csv(\"datasets/bbc-text.csv\")[\"text\"].values)\n",
    "\n",
    "new_text = [word_tokenize(story) for story in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "gkGm46I2xEDA"
   },
   "source": [
    "#### Train a New FastText Model Using the Corpus Available\n",
    "\n",
    "You can check the parameters available for you to tune [here](https://radimrehurek.com/gensim/models/fasttext.html#gensim.models.fasttext.FastText.train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "B36sZ2KlxEDA"
   },
   "outputs": [],
   "source": [
    "model = FastText(size=40, window=3, min_count=1)  # change the size of the windows\n",
    "model.build_vocab(new_text)\n",
    "model.train(new_text, total_examples=len(new_text), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "OC6vxECrxEDA",
    "outputId": "243bd74d-b1e1-4b81-de29-9fa8df516ed3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get corpus total count\n",
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "_S_O5kalxEDB",
    "outputId": "87769799-2e3b-4c46-cfec-cb5dab88d5e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0553882 , -0.76273805, -0.50317705, -0.06361123, -0.93174684,\n",
       "       -0.41743496, -0.11625393,  0.7774054 ,  1.2290146 , -0.5772658 ,\n",
       "        1.6802233 ,  0.28149393,  0.45046642, -0.27431312,  0.8296582 ,\n",
       "       -0.9890682 ,  2.1335685 ,  0.8600332 , -1.1994069 ,  1.0259854 ,\n",
       "        1.0035884 ,  1.0392529 ,  0.8607534 ,  0.18918608,  1.694635  ,\n",
       "        0.16429068, -0.9126573 ,  0.26494375, -0.06409768,  0.05012712,\n",
       "        0.2470527 , -1.4752648 , -0.8428264 , -0.6884603 ,  0.4806966 ,\n",
       "        0.06471832,  0.7640179 ,  0.5745636 , -0.24869992,  0.66379255],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get word vector for dog\n",
    "model.wv[\"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "wV7FTtNqxEDB",
    "outputId": "d0507b82-cb40-4505-f233-cc5592aac8d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get length of word embeddings\n",
    "len(model.wv[\"king\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "TKNEijOFxEDB",
    "outputId": "56b28d21-763f-41eb-909d-e617302ec480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('francesca', 0.9695392847061157), ('francesco', 0.9582855701446533), ('francique', 0.9312642812728882), ('franck', 0.9119763374328613), ('francs', 0.9090352058410645), ('franc', 0.900463879108429), ('iceland', 0.8946273326873779), ('maryland', 0.8929023742675781), ('icelandic', 0.8920712471008301), ('francisco', 0.8913147449493408)]\n",
      "\n",
      "\n",
      "[('kamiyama', 0.9355019330978394), ('jean-marie', 0.9155369997024536), ('xda', 0.909523606300354), ('jemma', 0.9086729288101196), ('jean-philippe', 0.9071090221405029), ('omaha', 0.9069798588752747), ('oe', 0.9063016176223755), ('jrfu', 0.9060392379760742), ('pyjama', 0.9027101993560791), ('zola', 0.9026373624801636)]\n",
      "\n",
      "\n",
      "[('transcript', 0.9141595363616943), ('storage', 0.9064804315567017), ('high-impact', 0.9003727436065674), ('high-visibility', 0.8945082426071167), ('high-capacity', 0.8868507146835327), ('high-quality', 0.8819433450698853), ('highly-radioactive', 0.8796373605728149), ('photo-real', 0.8777384757995605), ('pilgrimage', 0.877316951751709), ('technical', 0.8754753470420837)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(\"france\"))\n",
    "print(\"\\n\")\n",
    "print(model.wv.most_similar(\"aquaman\"))\n",
    "print(\"\\n\")\n",
    "print(model.wv.most_similar(\"transc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "qyaI_6VSxEDB"
   },
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "yrPv5zHwxEDB"
   },
   "source": [
    "### Distributed Memory Version of Paragraph Vector (PV-DM)\n",
    "![](https://github.com/ychennay/dso-560-nlp-text-analytics/blob/main/week5/images/doc2vec.png?raw=1)\n",
    "\n",
    "### Distributed Bag of Words of Paragraph Vector (PV-DBOW)\n",
    "![](https://github.com/ychennay/dso-560-nlp-text-analytics/blob/main/week5/images/doc2vec2.png?raw=1)\n",
    "[A Gentle Introduction to Doc2Vec](https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "LbpBhIPexEDB"
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(reviews)]\n",
    "model = Doc2Vec(documents, vector_size=50, window=4, min_count=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "0W-w4YI9xEDB"
   },
   "outputs": [],
   "source": [
    "doc1_vector = model.infer_vector([\"The\", \"toy\", \"was\", \"broken\", \"quickly\"]).reshape(1, -1)\n",
    "doc2_vector = model.infer_vector([\"It\", \"broke\", \"fast\"]).reshape(1, -1)\n",
    "doc3_vector = model.infer_vector([\"I ate lunch late\"]).reshape(1,-1)\n",
    "doc4_vector = model.infer_vector([\"It\", \"was\", \"crappy\", \"quality\"]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "DEYCzKDgxEDB"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "dNkhXb-NxEDB",
    "outputId": "0e3b10cd-22a6-439e-f946-0d55c69b021d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01620534]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(doc1_vector, doc2_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "YszhUrUixEDB",
    "outputId": "cefbca9b-fc3f-4e93-d219-6b715d334ca1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4734929]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(doc1_vector, doc3_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "FHplNb_2xEDB",
    "outputId": "e6d7164a-3a07-40e7-c109-e0e7afc1b37e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23254903]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(doc2_vector, doc3_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "li_bhqZ9xEDB",
    "outputId": "a4c2bb3a-ac00-496c-fb49-d1b9975317cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11511255]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(doc3_vector, doc4_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CW for week5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick 2 of the 4 true or false statements. If false, explain why and provide a real-life example.\n",
    "- You can use SVD to perform topic modelling by decomposing it into eigenvalues and eigenvectors.\n",
    "    - False. SVD decompose matrix into document matrix, strength matrix and terms matrix while PCA decompose matrix into eigenvalues and eigenvectors.\n",
    "- The values within an HMM's emission matrix represent the likelihood of seeing the word given a target class and each row should sum to 1.\n",
    "    - False. Each column should sum to 1.\n",
    "- The word sack would have different word2vec embedding value based on the context it is used in.\n",
    "    - False. Word2Vec embedding has a trained and fixed word matrix and therefore leads to same value for every word.\n",
    "- One of the benefits of reducing dimensions using SVD or PCA is improved feature explainability.\n",
    "    - False. Both SVD and PCA project data into some low dimension space where original features are no longer remained and therefore lose the feature interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPFmeJ8fxEDC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "nV5ojBE2xEC_",
    "R7ScfqnGxEDA",
    "UPvoExfzxEDA",
    "qyaI_6VSxEDB",
    "yrPv5zHwxEDB"
   ],
   "name": "word2vec (Part II).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.796875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
